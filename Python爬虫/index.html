<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Python爬虫 - JiZiTi | 学习管理
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <link href="//at.alicdn.com/t/font_1165120_w77ne6oe34j.css" rel="stylesheet" type="text/css">
    <!-- https://www.bootcdn.cn/mathjax/ -->
    
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> to be better </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar">
            <img src="/img/avatar.jpg">
        </div>
        <div class="name">
            <i>JiZiTi</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li>
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li>
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#response对象的属性"><span class="toc-text">response对象的属性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#requests处理异常"><span class="toc-text">requests处理异常</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Requests库的7个主要方法"><span class="toc-text">Requests库的7个主要方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#作业1"><span class="toc-text">作业1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#爬虫认识"><span class="toc-text">爬虫认识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实例爬取"><span class="toc-text">实例爬取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Beautiful-Soup"><span class="toc-text">Beautiful Soup</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#信息处理"><span class="toc-text">信息处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#大学排名实例"><span class="toc-text">大学排名实例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#正则表达式"><span class="toc-text">正则表达式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#淘宝商品比价定向爬虫实例"><span class="toc-text">淘宝商品比价定向爬虫实例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#股票数据定向爬虫实例"><span class="toc-text">股票数据定向爬虫实例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Scrapy框架"><span class="toc-text">Scrapy框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#股票爬虫Scrapy实例"><span class="toc-text">股票爬虫Scrapy实例</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input">
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i> to be better </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Python爬虫
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-04-28 20:18:55</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#collection" title="collection">collection</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>

    </div>
    <div class="post-content no-indent">
        <p><a href="https://www.icourse163.org/course/BIT-1001870001" target="_blank" rel="noopener">慕课学习</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br></pre></td></tr></table></figure>
<h4 id="response对象的属性"><a href="#response对象的属性" class="headerlink" title="response对象的属性"></a>response对象的属性</h4><ul>
<li>r = requests.get(url)</li>
<li>r.headers()</li>
<li>r.status_code = 200访问成功 = 404访问失败</li>
<li>r.encoding 根据headers猜测响应内容编码方式<br>如果headers中没有charset，则r.encoding = iso-8859-1</li>
<li>r.apparent_encoding根据内容猜测响应内容编码方式</li>
<li>r.text 打印页面内容</li>
<li>r.content 显示内容二进制形式（如图片资源）</li>
</ul>
<h4 id="requests处理异常"><a href="#requests处理异常" class="headerlink" title="requests处理异常"></a>requests处理异常</h4><ul>
<li>requests.ConnectionError 网络连接错误异常，如DNS查询失败、拒接连接等</li>
<li>requests.HTTPError HTTP错误异常<br>r.raise_for_status() 如果不是200，产生异常requests.HTTPError</li>
<li>requests.URLRequired URL缺失异常</li>
<li>requests.TooManyRedirects 超过最大重定向次数，产生重定向异常<br>对复杂连接进行访问</li>
<li>requests.ConnectTimeout 连接远程服务器超时异常</li>
<li>requests.Timeout 请求URL超时，产生超时异常</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">		r.raise_for_status() <span class="comment"># 如果状态码不是200，将产生异常</span></span><br><span class="line">		r.encoding = r.apparent_encoding</span><br><span class="line">		<span class="keyword">return</span> r.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>: <span class="comment"># 这个if语句起什么作用</span></span><br><span class="line">	url = <span class="string">"www.google.com"</span></span><br><span class="line">	print(getHTMLText(url))</span><br></pre></td></tr></table></figure>
<h4 id="Requests库的7个主要方法"><a href="#Requests库的7个主要方法" class="headerlink" title="Requests库的7个主要方法"></a>Requests库的7个主要方法</h4><ul>
<li><p>requests.request() 构造一个请求，支撑以下各种方法的基础方法<br><code>requests.request(method, url, 控制访问参数)</code><br>method: 请求方式，对应get/put/……/OPTIONS</p>
</li>
<li><p>requests.get() 最长使用方法</p>
</li>
<li>requests.head()</li>
<li>requests.post 附加新的数据</li>
<li>requests.put() 存储资源，覆盖原URL位置的资源</li>
<li>requests.patch() 提交局部修改请求</li>
<li>requests.delete()</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">访问控制参数演示</span></span><br><span class="line"><span class="string">params, data, json, headers, </span></span><br><span class="line"><span class="string">cookies, auth, files, timeout, proxies, </span></span><br><span class="line"><span class="string">allow_redirects, stream, verify, cert</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">payload = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, data = payload)</span><br><span class="line">print(r.text)</span><br><span class="line"></span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, json = payload)</span><br><span class="line">print(r.text)</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/post'</span>, params = payload)</span><br><span class="line">print(r.url)</span><br><span class="line"></span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, data = <span class="string">'ABC'</span>)</span><br><span class="line">print(r.text)</span><br><span class="line"></span><br><span class="line">fs = &#123;<span class="string">'file'</span>: open(<span class="string">'data.xls'</span>, <span class="string">'rb'</span>)&#125;</span><br><span class="line">r = requests.request(<span class="string">'POST'</span>, <span class="string">'http://python123.io/ws'</span>, files=fs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏IP</span></span><br><span class="line">pxs = &#123;<span class="string">'http'</span>: <span class="string">'http://user:pass@10.10.10.1:4321'</span></span><br><span class="line">       <span class="string">'http'</span>: <span class="string">'https://10.10.10.1:4321'</span>&#125;</span><br><span class="line">r = requests.request(<span class="string">'GET'</span>, <span class="string">'http://www.baidu.com'</span>, poxies=pxs)</span><br></pre></td></tr></table></figure>
<h4 id="作业1"><a href="#作业1" class="headerlink" title="作业1"></a>作业1</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">请编写一个小程序，“任意”找个url，测试一下成功爬取100次网页的时间。</span></span><br><span class="line"><span class="string">(某些网站对于连续爬取页面将采取屏蔽IP的策略，所以，要避开这类网站。)</span></span><br><span class="line"><span class="string">请回复代码，并给出url及在自己机器上的运行时间。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">		r.raise_for_status()</span><br><span class="line">		r.encoding = r.apparent_encoding</span><br><span class="line">		<span class="keyword">return</span> r.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>: <span class="comment"># 这个if语句起什么作用</span></span><br><span class="line">	url = <span class="string">"www.baidu.com"</span></span><br><span class="line">	s_time = datetime.datetime.now()</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100</span>):</span><br><span class="line">		getHTMLText(url)</span><br><span class="line">	e_time = datetime.datetime.now()</span><br><span class="line">	print(<span class="string">'运行时间：'</span>,(e_time-s_time).microseconds, end=<span class="string">'微秒'</span>)</span><br></pre></td></tr></table></figure>
<p>运行时间： 31499微秒</p>
<h4 id="爬虫认识"><a href="#爬虫认识" class="headerlink" title="爬虫认识"></a>爬虫认识</h4><ul>
<li>规模<ul>
<li>request库—小规模</li>
<li>scrapy库—中规模</li>
<li>搜索引擎—大规模</li>
</ul>
</li>
<li><p>网络爬虫的限制</p>
<ol>
<li>来源审查：判断User-Agent进行限制(浏览器)</li>
<li>发布公告：robots协议（根目录下放置robots.txt）</li>
</ol>
</li>
<li><p>Robots Exclusion Standard网络爬虫排除标准</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># hexo robots.txt</span><br><span class="line">User-agent: *                  //对于任意的agent都应遵守此协议</span><br><span class="line">Allow: /</span><br><span class="line">Allow: /archives/</span><br><span class="line">Allow: /categories/</span><br><span class="line">Allow: /tags/</span><br><span class="line"></span><br><span class="line">Disallow: /vendors/</span><br><span class="line">Disallow: /js/</span><br><span class="line">Disallow: /css/</span><br><span class="line">Disallow: /fonts/</span><br><span class="line">Disallow: /vendors/</span><br><span class="line">Disallow: /fancybox/</span><br><span class="line"></span><br><span class="line">User-agent: EtaoSpider        //此指名的恶意爬虫</span><br><span class="line">Disallow: /                   //不能爬取根目录下的所有文件</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="实例爬取"><a href="#实例爬取" class="headerlink" title="实例爬取"></a>实例爬取</h4><ul>
<li>一般性爬取</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLJD</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text[:<span class="number">1000</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"爬取失败"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLAMS</span><span class="params">(url)</span>:</span> <span class="comment"># 简单伪装</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">        <span class="comment"># 'User-Agent': 'python-requests/2.21.0'模拟浏览器</span></span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>, headers=kv)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text[<span class="number">1000</span>:<span class="number">2000</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"爬取失败"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    urlJD = <span class="string">"https://item.jd.com/2967929.html"</span>  <span class="comment"># 京东</span></span><br><span class="line">    urlAMS = <span class="string">"https://www.amazon.cn/gp/product/B01M8L5Z3Y"</span>  <span class="comment"># 亚马逊</span></span><br><span class="line">    print(getHTMLJD(urlJD))</span><br><span class="line">    print(getHTMLAMS(urlAMS))</span><br></pre></td></tr></table></figure>
<ul>
<li>搜索引擎关键词提交接口<ol>
<li>百度：<a href="http://www.baidu.com/s?wd=keyword" target="_blank" rel="noopener">http://www.baidu.com/s?wd=keyword</a></li>
<li>360：<a href="http://www.so.com/s?q=keyword" target="_blank" rel="noopener">http://www.so.com/s?q=keyword</a></li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLBaidu</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        kv = &#123;<span class="string">'wd'</span>: <span class="string">'Python'</span>&#125;</span><br><span class="line">        r = requests.get(url, params=kv)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> len(r.text)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"爬取失败"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTML360</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        kv = &#123;<span class="string">'q'</span>: <span class="string">'Python'</span>&#125;</span><br><span class="line">        r = requests.get(url, params=kv)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> len(r.text)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"爬取失败"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    urlBaidu = <span class="string">"http://www.baidu.com/s"</span>  <span class="comment"># 百度</span></span><br><span class="line">    url360 = <span class="string">"http://www.so.com/s"</span>  <span class="comment"># 360</span></span><br><span class="line">    print(getHTMLBaidu(urlBaidu))</span><br><span class="line">    print(getHTML360(url360))</span><br></pre></td></tr></table></figure>
<ul>
<li>网络图片等资源下载</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.jiziti.fun/img/avatar.jpg"</span></span><br><span class="line">root = <span class="string">"D://test//"</span></span><br><span class="line">path = root + url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(r.content)  <span class="comment"># r.content返回2进制文件</span></span><br><span class="line">            f.close()</span><br><span class="line">            print(<span class="string">"文件成功保存"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"文件已经存在"</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>IP地址归属地的自动查询</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"http://m.ip138.com/ip.asp?ip="</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    r = requests.get(url + <span class="string">'202.204.80.112'</span>)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(r.text[<span class="number">-500</span>:])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a><a href="https://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noopener">Beautiful Soup</a></h4><p>可以解析html和xml文档</p>
<p><code>pip install beautifulsoup4</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"http://python123.io/ws/demo.html"</span>)</span><br><span class="line">demo = r.text</span><br><span class="line">soup = BeautifulSoup(demo, <span class="string">'html.parser'</span>) <span class="comment"># HTML解析器</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup('&lt;p&gt;data&lt;/p&gt;', 'html.parser')</span></span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Beautiful Soup库解析器</p>
<ol>
<li>html.parser <code>不用再安装其他包</code></li>
<li>lxml <code>pip install lxml</code></li>
<li>xml  <code>pip install lxml</code></li>
<li>html5lib <code>pip install html5lib</code></li>
</ol>
</li>
<li><p>Beautiful Soup类的基本元素</p>
<ol>
<li>Tag</li>
<li>Name <code>&lt;tag&gt;.name</code></li>
<li>Attributes <code>&lt;tag&gt;.attrs</code></li>
<li>NavigableString <code>&lt;tag&gt;.string</code></li>
<li>Comment 注释部分处理</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">soup.title <span class="comment"># &lt;title&gt;This is a python demo page&lt;/title&gt;</span></span><br><span class="line">tag = soup.a</span><br><span class="line">tag</span><br><span class="line">type(tag) <span class="comment"># &lt;class 'bs4.element.Tag'&gt;</span></span><br><span class="line"></span><br><span class="line">soup.a.name <span class="comment"># 'a'</span></span><br><span class="line">soup.a.parent.name <span class="comment"># 'p'</span></span><br><span class="line">soup.a.parent.parent.name <span class="comment"># 'body'</span></span><br><span class="line"></span><br><span class="line">tag.attrs <span class="comment"># &#123;'href': 'http://www.icourse163.org/course/BIT-268001', 'class': ['py1'], 'id': 'link1'&#125;</span></span><br><span class="line">type(tag.attrs) <span class="comment"># &lt;class 'dict'&gt;</span></span><br><span class="line">tag.attrs[<span class="string">'class'</span>] <span class="comment"># ['py1']</span></span><br><span class="line"></span><br><span class="line">newsoup = BeautifulSoup(<span class="string">'&lt;p&gt;&lt;b&gt;&lt;!-- test --&gt;&lt;/b&gt;&lt;/p&gt;'</span>,<span class="string">'html.parser'</span>)</span><br><span class="line">newsoup.b.string <span class="comment"># ' test '</span></span><br><span class="line">newsoup.p.string <span class="comment"># ' test '</span></span><br><span class="line">type(newsoup.b.string) <span class="comment"># &lt;class 'bs4.element.Comment'&gt;</span></span><br><span class="line">type(newsoup.p.string) <span class="comment"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>遍历</p>
<ul>
<li>向下遍历<ol>
<li>contents 子节点的列表</li>
<li>children 子节点的迭代类型</li>
<li>descendants 子孙节点的迭代类型</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">soup.head <span class="comment"># &lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line">soup.head.contents <span class="comment"># [&lt;title&gt;This is a python demo page&lt;/title&gt;]</span></span><br><span class="line"><span class="comment"># '\n'也是一个节点</span></span><br></pre></td></tr></table></figure>
<ul>
<li>向上遍历<ol>
<li>parent 父节点的标签 (html标签的父亲是其本身)</li>
<li>parents 节点先辈标签的迭代类型</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.a.parents:</span><br><span class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        print(parent) <span class="comment"># soup本身会被遍历，soup.parent为空</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(parent.name)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>平行遍历</p>
<p><strong>平行遍历发生在同一个父节点下</strong></p>
<ol>
<li>next_sibling 下一个平行节点的标签</li>
<li>previous_sibling 上一个平行节点的标签</li>
<li>next_siblings 后续平行标签的迭代类型</li>
<li>previous_siblings 前面平行标签的迭代类型</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">soup.a.next_sibling</span><br><span class="line"><span class="comment"># ' and ' NavigableString是一个节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">    print(sibling)</span><br></pre></td></tr></table></figure>
</li>
<li><p>其他</p>
<p>HTML打印prettify()<br>支持中文utf-8</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soup.prettify() <span class="comment"># 给每一个标签后面加一个换行符</span></span><br><span class="line">print(soup.a.prettify())</span><br></pre></td></tr></table></figure>
<h4 id="信息处理"><a href="#信息处理" class="headerlink" title="信息处理"></a>信息处理</h4><ul>
<li><p>信息标记</p>
<ul>
<li>xml</li>
<li>json（javascript object notation)</li>
<li>yaml</li>
</ul>
</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">person</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">firstName</span>&gt;</span>Tian<span class="tag">&lt;/<span class="name">firstName</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">lastName</span>&gt;</span>Song<span class="tag">&lt;/<span class="name">lastName</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">address</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">streetAddr</span>&gt;</span>中关村南大街<span class="tag">&lt;/<span class="name">streetAddr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">city</span>&gt;</span>北京<span class="tag">&lt;/<span class="name">city</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">zipcode</span>&gt;</span>100080<span class="tag">&lt;/<span class="name">zipcode</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">address</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">prof</span>&gt;</span>Computer System<span class="tag">&lt;/<span class="name">prof</span>&gt;</span><span class="tag">&lt;<span class="name">prof</span>&gt;</span>Security<span class="tag">&lt;/<span class="name">prof</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">person</span>&gt;</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"firstName"</span>: <span class="string">"Tian"</span>,</span><br><span class="line">    <span class="attr">"lastName"</span>: <span class="string">"Song"</span>,</span><br><span class="line">    <span class="attr">"address"</span>: &#123;</span><br><span class="line">        <span class="attr">"streetAddr"</span>: <span class="string">"中关村南大街"</span>,</span><br><span class="line">        <span class="attr">"city"</span>: <span class="string">"北京"</span>,</span><br><span class="line">        <span class="attr">"zipcode"</span>: <span class="string">"100080"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"prof"</span>: [<span class="string">"Computer System"</span>, <span class="string">"Security"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">firstName:</span> <span class="string">Tian</span> <span class="comment"># 无类型的键值对</span></span><br><span class="line"><span class="attr">lastName:</span> <span class="string">Song</span></span><br><span class="line"></span><br><span class="line"><span class="attr">address:</span> <span class="comment"># 通过缩进表达所属关系</span></span><br><span class="line">	<span class="attr">streetAddr:</span> <span class="string">中关村南大街</span></span><br><span class="line">	<span class="attr">city:</span> <span class="string">北京</span></span><br><span class="line">	<span class="attr">zipcode:</span> <span class="number">100080</span></span><br><span class="line"></span><br><span class="line"><span class="attr">prof:</span> <span class="comment"># -表示并列</span></span><br><span class="line"><span class="bullet">-</span><span class="string">Computer</span> <span class="string">System</span></span><br><span class="line"><span class="bullet">-</span><span class="string">Security</span></span><br><span class="line"></span><br><span class="line"><span class="attr">text:</span> <span class="string">| # 表达整块数据</span></span><br><span class="line"><span class="string">这是一段很长的文本这是一段很长的文本这是一段很长的文本这是一段很长的文本这是一段很长的文本这是一段很长的文本这是一段很长的文本这是一段很长的文本这是一段很长的文本</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>提取关键信息</p>
<ol>
<li><p>解析信息</p>
</li>
<li><p>直接搜索关键信息（准确性低）</p>
</li>
<li><p>融合两种方法</p>
</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"http://python123.io/ws/demo.html"</span>)</span><br><span class="line">demo = r.text</span><br><span class="line">soup = BeautifulSoup(demo, <span class="string">'html.parser'</span>) <span class="comment"># HTML解析器</span></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">'a'</span>):</span><br><span class="line">    print(link.get(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li>beautifulsoup的方法<ul>
<li><code>find_all(name, attrs, recursive, string, 其他控制)</code><br>这个attrs直接用的话指的是class而不是id<br>如果查找id，需要<code>id=&#39;×××&#39;</code><br>recursive：是否对子孙全部检索，默认为True<br>string：字符串域的特定检索<br><code>import re</code>结合正则表达式使用<br>find_all可省略</li>
<li>扩展方法<br>find()：只返回一个结果，字符串类型<br>find_parents()：先辈节点，列表类型<br>find_parent()：一个结果，字符串类型<br>find_next_siblings()<br>find_next_sibling()<br>find_previous_siblings()<br>find_previous_sibling()</li>
</ul>
</li>
</ul>
<h4 id="大学排名实例"><a href="#大学排名实例" class="headerlink" title="大学排名实例"></a>大学排名实例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span> <span class="comment"># 从网络上获取大学排名的网页内容</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="string">"获取异常"</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span> <span class="comment"># 将信息存储在列表中</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag): <span class="comment"># 过滤掉非标签类型</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>) <span class="comment"># 省略find_all</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].string, tds[<span class="number">3</span>].string])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span> <span class="comment"># 输出结果</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span> <span class="comment"># 使用&#123;3&#125;的参数填充</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    ulist = []</span><br><span class="line">    url = <span class="string">'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2019.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(ulist, html)</span><br><span class="line">    printUnivList(ulist, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h4 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h4><div class="table-container">
<table>
<thead>
<tr>
<th>操作符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>任何单个字符</td>
</tr>
<tr>
<td>[]</td>
<td>字符集，对单个字符给出取值范围</td>
</tr>
<tr>
<td><sup><a href="#fn_" id="reffn_"></a></sup></td>
<td>非字符集，对单个字符给出排除范围</td>
</tr>
<tr>
<td>*</td>
<td>前一个字符0次或无限次扩展</td>
</tr>
<tr>
<td>+</td>
<td>前一个字符1次或无限次扩展</td>
</tr>
<tr>
<td>?</td>
<td>前一个字符0次或1次扩展</td>
</tr>
<tr>
<td>&#x7C;</td>
<td>左右表达式任意一个</td>
</tr>
<tr>
<td>{m}</td>
<td>扩展前一个字符m次</td>
</tr>
<tr>
<td>{m,n}</td>
<td>扩展前一个字符m至n次（含n）</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串开头</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串结尾</td>
</tr>
<tr>
<td>()</td>
<td>分组标记，内部只能使用&#124;操作符</td>
</tr>
<tr>
<td>\d</td>
<td>数字，等价于[0-9]</td>
</tr>
<tr>
<td>\w</td>
<td>单词字符，等价于[A-Za-z0-9_]</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>常用正则表达式<ul>
<li><code>^[A-Za-z]+$</code><br>由26个字母组成的字符串</li>
<li><code>^[A-Za-z0-9]+$</code><br>由26个字母和数字组成的字符串</li>
<li><code>^-?\d+$</code><br>整数形式的字符串</li>
<li><code>^[0-9]*[1-9][0-9]*$</code><br>正整数形式的字符串<or>？？？</or></li>
<li><code>[1-9]\d{5}</code><br>中国境内邮政编码，6位</li>
<li><code>[\u4e00-\u9fa5]</code><br>匹配中文字符</li>
<li><code>\d{3}-\d{8}|\d{4}-\d{7}</code><br>国内电话号码，010-68913536</li>
<li><code>(([1-9]?\d|1\d{2}|2[0-4]\d|25[0-5]).){3}([1-9]?\d|1\d{2}|2[0-4]\d|25[0-5])</code><br>匹配IP地址<br>0-99:<code>[1-9]?\d</code> 100-199: <code>1\d{2}</code> 200-249: <code>2[0-4]\d</code> 250-255: <code>25[0-5]</code></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure>
<ul>
<li><p>正则表达式的表示类型</p>
<ol>
<li>raw string类型（\不解释为转义符）<br>如：<code>r[1-9]\d{5}</code></li>
<li>string类型<br>如：<code>[1-9]\\d{5}</code></li>
</ol>
</li>
<li><p>re库的主要功能函数</p>
<ol>
<li>re.search(pattern, string, flags=0) 匹配第一个，返回match对象<br>re.I(ignorecase)匹配忽略大小写<br>re.M(multiline) ^操作符将匹配每行开始部分<br>re.S(dotall) .操作符能够匹配所有字符（包括换行符）</li>
<li>re.match(pattern, string, flags=0) 从开始位置匹配，返回match对象</li>
<li>re.findall(pattern, string, flags=0) 匹配所有，返回列表</li>
<li>re.split(pattern, string, maxsplit=0, flags=0) 返回列表<br>maxsplit：最大分割数，剩余部分作为最后一个元素输出</li>
<li>re.finditer(pattern, string, flags=0) 返回迭代类型，迭代元素为match对象</li>
<li>re.sub(pattern, repl, string, count=0, flags=0) 返回替换后的字符串<br>count：匹配的最大替换次数</li>
</ol>
</li>
<li><p>编译执行</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多次使用pattern</span></span><br><span class="line">rex = re.compile(<span class="string">r'[1-9]\d&#123;5&#125;'</span>)</span><br><span class="line">rst = rex.search(<span class="string">'BTS 100086'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Match对象的属性与方法</p>
<ol>
<li>string 待匹配字符串；re 正则表达式；pos 搜索字符串的开始位置；endpos</li>
<li>group(0)；start()；end()；span() 返回(.start(), .end())元组类型</li>
</ol>
</li>
<li><p>贪婪匹配与最小匹配</p>
<ul>
<li><code>*?</code>、<code>+?</code>、<code>??</code>、<code>{m,n}?</code></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">match = re.search(<span class="string">r'PY.*N'</span>,<span class="string">'PYANBNCNDN'</span>)</span><br><span class="line">match.group(<span class="number">0</span>) <span class="comment"># 默认采用贪婪模式，返回'PYANBNCNDN'</span></span><br><span class="line">match = re.search(<span class="string">r'PY.*?N'</span>,<span class="string">'PYANBNCNDN'</span>)</span><br><span class="line">match.group(<span class="number">0</span>) <span class="comment"># 通过？实现最小匹配，返回'PYAN'</span></span><br></pre></td></tr></table></figure>
<h4 id="淘宝商品比价定向爬虫实例"><a href="#淘宝商品比价定向爬虫实例" class="headerlink" title="淘宝商品比价定向爬虫实例"></a>淘宝商品比价定向爬虫实例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        kv = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0'</span>,</span><br><span class="line">            <span class="string">'Cookie'</span>: <span class="string">'××××'</span>, <span class="comment"># 可手动获取</span></span><br><span class="line">        &#125;</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>, headers=kv) <span class="comment"># 淘宝模拟登录</span></span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">     </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parsePage</span><span class="params">(ilt, html)</span>:</span> <span class="comment"># 提取商品名称和价格信息</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        plt = re.findall(<span class="string">r'\"view_price\"\:\"[\d\.]*\"'</span>,html)</span><br><span class="line">        tlt = re.findall(<span class="string">r'\"raw_title\"\:\".*?\"'</span>,html)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(plt)):</span><br><span class="line">            price = eval(plt[i].split(<span class="string">':'</span>)[<span class="number">1</span>]) <span class="comment"># eval函数去掉单双引号</span></span><br><span class="line">            title = eval(tlt[i].split(<span class="string">':'</span>)[<span class="number">1</span>])</span><br><span class="line">            ilt.append([price , title])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"parsePage出错"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printGoodsList</span><span class="params">(ilt)</span>:</span> <span class="comment"># 输出结果</span></span><br><span class="line">    tplt = <span class="string">"&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"序号"</span>, <span class="string">"价格"</span>, <span class="string">"商品名称"</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> ilt:</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">        print(tplt.format(count, g[<span class="number">0</span>], g[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    goods = <span class="string">'书包'</span></span><br><span class="line">    depth = <span class="number">2</span> <span class="comment"># 爬取多少页</span></span><br><span class="line">    start_url = <span class="string">'https://s.taobao.com/search?q='</span> + goods</span><br><span class="line">    infoList = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth): <span class="comment"># 循环获取页面</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = start_url + <span class="string">'&amp;s='</span> + str(<span class="number">44</span>*i) <span class="comment"># 淘宝每页显示44个商品</span></span><br><span class="line">            html = getHTMLText(url)</span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    printGoodsList(infoList)</span><br><span class="line">     </span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p><img src="../img/loading.gif" data-original="/img/python/2.png" alt="输出结果"></p>
<h4 id="股票数据定向爬虫实例"><a href="#股票数据定向爬虫实例" class="headerlink" title="股票数据定向爬虫实例"></a>股票数据定向爬虫实例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> traceback <span class="comment"># 为了调试方便</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url, code=<span class="string">"utf-8"</span>)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = code <span class="comment"># 手工获取encoding，提高运行效率</span></span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStockList</span><span class="params">(lst, stockURL)</span>:</span> <span class="comment"># 获取股票列表</span></span><br><span class="line">    html = getHTMLText(stockURL, <span class="string">"GB2312"</span>)</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'html.parser'</span>) </span><br><span class="line">    a = soup.find_all(<span class="string">'a'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            href = i.attrs[<span class="string">'href'</span>]</span><br><span class="line">            lst.append(re.findall(<span class="string">r"[s][hz]\d&#123;6&#125;"</span>, href)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStockInfo</span><span class="params">(lst, stockURL, fpath)</span>:</span> <span class="comment"># 根据股票雷柏啊在百度获取个股信息</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> stock <span class="keyword">in</span> lst:</span><br><span class="line">        url = stockURL + stock + <span class="string">".html"</span></span><br><span class="line">        html = getHTMLText(url)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> html==<span class="string">""</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            infoDict = &#123;&#125;</span><br><span class="line">            soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">            stockInfo = soup.find(<span class="string">'div'</span>,attrs=&#123;<span class="string">'class'</span>:<span class="string">'stock-bets'</span>&#125;)</span><br><span class="line"> </span><br><span class="line">            name = stockInfo.find_all(attrs=&#123;<span class="string">'class'</span>:<span class="string">'bets-name'</span>&#125;)[<span class="number">0</span>]</span><br><span class="line">            infoDict.update(&#123;<span class="string">'股票名称'</span>: name.text.split()[<span class="number">0</span>]&#125;)</span><br><span class="line">             </span><br><span class="line">            keyList = stockInfo.find_all(<span class="string">'dt'</span>)</span><br><span class="line">            valueList = stockInfo.find_all(<span class="string">'dd'</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(keyList)):</span><br><span class="line">                key = keyList[i].text</span><br><span class="line">                val = valueList[i].text</span><br><span class="line">                infoDict[key] = val</span><br><span class="line">             </span><br><span class="line">            <span class="keyword">with</span> open(fpath, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write( str(infoDict) + <span class="string">'\n'</span> )</span><br><span class="line">                count = count + <span class="number">1</span></span><br><span class="line">                print(<span class="string">"\r当前进度: &#123;:.2f&#125;%"</span>.format(count*<span class="number">100</span>/len(lst)),end=<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="comment">#traceback.print_exc()</span></span><br><span class="line">            count = count + <span class="number">1</span> <span class="comment"># 显示进度，\r实现不换行</span></span><br><span class="line">            print(<span class="string">"\r当前进度: &#123;:.2f&#125;%"</span>.format(count*<span class="number">100</span>/len(lst)),end=<span class="string">""</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    stock_list_url = <span class="string">'http://quote.eastmoney.com/stock_list.html'</span></span><br><span class="line">    stock_info_url = <span class="string">'https://gupiao.baidu.com/stock/'</span></span><br><span class="line">    output_file = <span class="string">'D:/BaiduStockInfo.txt'</span></span><br><span class="line">    slist=[]</span><br><span class="line">    getStockList(slist, stock_list_url)</span><br><span class="line">    getStockInfo(slist[<span class="number">200</span>:<span class="number">230</span>], stock_info_url, output_file)</span><br><span class="line"> </span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h4 id="Scrapy框架"><a href="#Scrapy框架" class="headerlink" title="Scrapy框架"></a>Scrapy框架</h4><p><code>pip install scrapy</code></p>
<p><img src="../img/loading.gif" data-original="/img/python/3.png" alt="scrapy"></p>
<ul>
<li><p>“5+2”结构</p>
<ol>
<li>engine：控制所有模块之间的数据流，根据条件触发事件</li>
<li>downloader：根据请求下载网页</li>
<li>scheduler：调度爬取请求</li>
<li>downloader middleware：修改、丢弃、新增请求或响应（request、response）</li>
<li>spider：提供初始url，解析response，产生item，产生额外的request</li>
<li>item pipelines：对item进行处理</li>
<li>spider middleware</li>
</ol>
</li>
<li><p>命令行使用</p>
<p><code>scrapy &lt;command&gt;[options][args]</code></p>
<ol>
<li><code>scrapy startproject [options]&lt;name&gt;&lt;domain&gt;</code>创建工程</li>
<li><code>scrapy genspider&lt;name&gt;[dir]</code>创建爬虫</li>
<li><code>scrapy settings[options]</code>获取爬虫配置信息</li>
<li><code>scrapy crawl&lt;spider&gt;</code>运行爬虫</li>
<li><code>scrapy list</code>列出工程中的所有爬虫</li>
<li><code>scrapy shell [url]</code>启动URL调试命令行</li>
</ol>
</li>
<li><p>实例</p>
<ol>
<li><p><code>scrapy startproject spy</code><br><code>cd spy</code></p>
</li>
<li><p><code>scrapy genspider demo spy.io</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'demo'</span> <span class="comment"># 爬虫名字</span></span><br><span class="line">    allowed_domains = [<span class="string">'spy.io'</span>] <span class="comment"># 爬取域名</span></span><br><span class="line">    start_urls = [<span class="string">'http://spy.io/'</span>] <span class="comment"># 初始爬取也秒</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#parse用于处理响应，解析内容形成字典，发现新的URL爬取请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改demo.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"demo"</span></span><br><span class="line">    <span class="comment">#allowed_domains = ["python123.io"]</span></span><br><span class="line">    start_urls = [<span class="string">'https://python123.io/ws/demo.html'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        fname = response.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>] <span class="comment"># 写入response内容</span></span><br><span class="line">        <span class="keyword">with</span> open(fname, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Saved file %s.'</span> % name)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>scrapy crawl demo</code></p>
</li>
</ol>
</li>
<li><p>yield生成器<br>节省存储空间<br>常与for循环结合使用</p>
</li>
<li><p>CSS Selector<br><code>&lt;HTML&gt;.css(&#39;a::attr(href)&#39;).extract()</code></p>
</li>
</ul>
<h4 id="股票爬虫Scrapy实例"><a href="#股票爬虫Scrapy实例" class="headerlink" title="股票爬虫Scrapy实例"></a>股票爬虫Scrapy实例</h4><ul>
<li>stocks.py（spider）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StocksSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"stocks"</span></span><br><span class="line">    start_urls = [<span class="string">'http://quote.eastmoney.com/stock_list.html'</span>]</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'a::attr(href)'</span>).extract():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                stock = re.findall(<span class="string">r"[s][hz]\d&#123;6&#125;"</span>, href)[<span class="number">0</span>]</span><br><span class="line">                url = <span class="string">'https://gupiao.baidu.com/stock/'</span> + stock + <span class="string">'.html'</span></span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse_stock)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_stock</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        infoDict = &#123;&#125; <span class="comment"># item类似字典</span></span><br><span class="line">        stockInfo = response.css(<span class="string">'.stock-bets'</span>)</span><br><span class="line">        name = stockInfo.css(<span class="string">'.bets-name'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        keyList = stockInfo.css(<span class="string">'dt'</span>).extract()</span><br><span class="line">        valueList = stockInfo.css(<span class="string">'dd'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(keyList)):</span><br><span class="line">            key = re.findall(<span class="string">r'&gt;.*&lt;/dt&gt;'</span>, keyList[i])[<span class="number">0</span>][<span class="number">1</span>:<span class="number">-5</span>]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                val = re.findall(<span class="string">r'\d+\.?.*&lt;/dd&gt;'</span>, valueList[i])[<span class="number">0</span>][<span class="number">0</span>:<span class="number">-5</span>]</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                val = <span class="string">'--'</span></span><br><span class="line">            infoDict[key]=val</span><br><span class="line"> </span><br><span class="line">        infoDict.update(</span><br><span class="line">            &#123;<span class="string">'股票名称'</span>: re.findall(<span class="string">'\s.*\('</span>,name)[<span class="number">0</span>].split()[<span class="number">0</span>] + \</span><br><span class="line">             re.findall(<span class="string">'\&gt;.*\&lt;'</span>, name)[<span class="number">0</span>][<span class="number">1</span>:<span class="number">-1</span>]&#125;)</span><br><span class="line">        <span class="keyword">yield</span> infoDict <span class="comment"># 将信息提交给item piplines类</span></span><br></pre></td></tr></table></figure>
<ul>
<li>pipelines.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaidustocksPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaidustocksInfoPipeline</span><span class="params">(object)</span>:</span> <span class="comment"># 处理stocks类中提交的item</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.f = open(<span class="string">'BaiduStockInfo.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.f.close()</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            line = str(dict(item)) + <span class="string">'\n'</span></span><br><span class="line">            self.f.write(line)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<ul>
<li>settings.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'BaiduStocks.pipelines.BaidustocksInfoPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="../img/loading.gif" data-original="/img/python/4.png" alt="输出结果"></p>

        <a id="gotop" href="#"><i class="iconfont icon-up-circle"></i></a>
        
        <br>
        <div id="gitalk-container"></div>
    </div>
</div>
    </div>
</div>

<footer class="footer">
    <ul class="list-inline text-center">
        <li>
            <a target="_blank" href="https://xn--i0v668g.com/">
                            <span>
                                <i class="iconfont icon-yang"></i>
                            </span>
            </a>
        </li>
        

        

        

        

        

    </ul>
    
    <p>
	to work harder
        <!-- 
	<span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span> 
----------------------------����if you are looking for my theme����---------------------------
	<a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a>
----------------------------------------------------------------------------------------------
	-->
        <a href="https://hexo.io/">Hexo</a></p>
</footer><!-- hexo-inject:begin --><!-- hexo-inject:end -->




<script>!function(e){var r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function t(){for(var c=0;c<r.length;c++)t=r[c],void 0,0<=(n=t.getBoundingClientRect()).top&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=r[c];t=o,n=function(){r=r.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}t(),e.addEventListener("scroll",function(){!function(t,n){clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)}(t,e)})}(this);</script></body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<!--Leancloud 操作库:-->
<script src='//cdn1.lncld.net/static/js/3.0.4/av-min.js'/>
<!--Valine 的核心代码库:-->
<script src="./dist/Valine.min.js"></script>
<script src="/js/gitment.js"></script>


</html>
