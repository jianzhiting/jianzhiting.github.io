[{"title":"Hadoop","url":"/2019/04/Hadoop/","content":"\n# 基于MR的Kindle评论数据分析\n\n## **1**    **项目简介**\n\n### **1.1**    **背景**\n\n随着Web技术和电子商务的发展，越来越多的人会在线上对自己买过的商品发表评论。这些评论信息虽然可能会带着一些发布者的主观情感，但是能在一定程度上反映出商品的好坏以及顾客对商品的喜爱程度。基于大数据分析技术，能够从大量评论数据中分析出商品的整体评价、评论者的评论偏好等。如果能够去除评论中各种因素带来的偏差，得到的结果将能够更加准确地反映事实。\n\n商家得到从大量评论数据中分析出的顾客反馈后，将有助于商家进行销售策略的决策，而其他准备购买该商品的顾客也可以根据评论的反馈来帮助自己判断该商品是否值得购买。\n\n### **1.2**    **项目实现目的**\n\n基于MapReduce算法，通过不断地修改分析评论数据的标准来得到更加真实的分析结果。先通过分析不同时间粒度、不同评论星级下的评论分布以及各级评分商品的评论情况来得到数据的基本情况。在此基础上修正评分模型，剔除“水军”、对评论进行情感分析，结合时效性和帮助性来得到更加真实准确的评论情况。\n\n### **1.3**    **整体思路**\n\n本项目旨在分析亚马逊kindle商店1996年到2014年的百万条评论数据，修正评分模型从而得到更为真实准确的评论情况。分析过程分为以下步骤：\n\n（1）  针对评论原始数据（一级数据）进行分析，得到不同时间粒度下的评论分布、各个阶段评论的词云等二级数据。\n\n（2）  求出不同标准下的各个商品的平均评级作为基准对比数据。\n\n（3）  在基准数据的基础上，识别出评论中的“水军”，根据帮助度和时效性确定每条评论评级的权重，对评论进行情感识别分析，去除不同人之间的偏好评分差异，修正评分模型，重新对一级数据进行分析，得到更加准确的结果。\n\n以上的步骤都是基于Hadoop MapReduce编程求解，得出分析结果后使用Python制作出图表。\n\n最后，本文列出了各个阶段的分析结果。\n\n## **2**    **数据及集群配置说明**\n\n### **2.1**    **数据来源**\n\n我们从kaggle网站下载了有关亚马逊的kindle商店产品的评论数据，评论时间从1996年5月到2014年7月，总共982619条，其中每个评论者至少发布了5条评论，每个产品都至少有5条评论。\n\n### **2.2**    **数据结构说明**\n\n**数据格式****;** json\n\n**数据字段：**\n\n| 名称           | 解释           |\n| -------------- | -------------- |\n| asin           | 产品编号       |\n| helpful        | 评论是否有帮助 |\n| overall        | 产品评级       |\n| reviewText     | 评论内容       |\n| reviewTime     | 评论时间       |\n| reviewerID     | 评论者ID       |\n| reviewerName   | 评论者名称     |\n| summary        | 评论内容的概括 |\n| unixReviewTime | 时间戳         |\n\n注：helpful：[m,n]表示有n个人对这条评论进行了评价，其中m个人认为这条评论有帮助。\n\n**数据实例：**\n\n{\"reviewerID\":\"A1F6404F1VG29J\",\"asin\":\"B000F83SZQ\", reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"}\n\n### **2.3**    **集群配置说明**\n\n**集群搭建情况：**\n\n| 机器名称 | IP地址        | 硬件配置                |\n| -------- | ------------- | ----------------------- |\n| Master   | 192.168.1.246 | Core i5 双核   RAM:12GB |\n| Slaver0  | 192.168.1.243 | Core i5 双核   RAM:8GB  |\n| Slaver1  | 192.168.1.245 | Core i5 双核 RAM:8GB    |\n| Slaver2  | 192.168.1.247 | Core i5 双核   RAM:8GB  |\n\n\n\n**软件：**\n\n| 名称                   | **版本** |\n| ---------------------- | -------- |\n| Hadoop                 | 2.9.0    |\n| Ubuntu                 | 16.04.5  |\n| VMware Workstation Pro | 12.1.0   |\n| Python                 | 3.6.4    |\n| Maven                  | 3.6.0    |\n\n## **3**    **数据概览**\n\n经统计，共有评论者68223人，商品61934种。同时，没有同一评论者为同一商品留评超过两次。\n\n### **3.1**    **不同时间粒度下的评论分布**\n\n首先，在该案例中，我们首先需要了解在不同时间下评论数目的分布，从而对用户的活跃情况有一个初步认识，因为评论数目一定程度上影响了Kindle书籍的销售数目，因此提高Kindle用户的活跃度，可以提高Kindle书籍的销售情况。\n\n具体处理流程如下：\n\n1.入初始数据，根据评论的UNIX时间戳进行统计，以天作为时间粒度（原始数据中UNIX时间戳缺乏精细到小时的数据），统计出不同日期的评论数目。用例如下：\n\n**·参考代码****CommentCountByDate.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: 2000-03-05(评论日期)   value: 1（评论次数）\n\n2.在获取以天作为时间粒度，2000~2014年不同日期的评论数目后，利用Python统计出不同年份、月份、工作日的日平均评论数目：\n\n将统计结果绘制成折线图如下:\n\n![img](/img/hadoop/output_3_0.png)\n\n从上图中可以看出，Kindle的评论数目自从2010年开始呈现井喷式增长，最终在2014年达到日平均数目为2000次。这可能是因为随着移动互联网的发展，更多的人选择在kindle上购买电子书；\n\n![img](/img/hadoop/output_4_0.png)\n\n从上图中可以看出，日平均评论数目在1月份至7月份在525次上下波动；在8-12月份与之前相比显著下降，但仍然呈现出回升趋势。这可能是因为人们在年初的时候会一次性购买今年要阅读的书籍；\n\n![img](/img/hadoop/output_5_0.png)\n\n从上图中可以看出，在周日、周一时，日平均评论数目与平时相比较高。这可能是因为在周日、周一等人们有较多空闲的时间来阅读书籍和对书籍进行评论。\n\n因此，Kindle销售部门可在8-12月份增加促销活动；在周日、周一等人们有较多空闲的时间，增加商品推送，从而，提高Kindle书籍销量。\n\n### **3.2**   **各阶段评分商品的评论关键词**\n\n在获取不同商品的评分后，为分析不同评论的内容对商品评分的影响 ，我们根据商品评分的不同划分为五个区间 [1,2), [2,3), [3,4), [4,5)，[5,5]根据TF-IDF方法提取出每个评论的关键词，并统计不同评分区间下关键词的分布，绘制成图云加以展示。\n\n具体处理流程如下：\n\n**·参考代码****CommentTermFrequency.java**\n\n1.在对评论进行分词并去除stopword后，计算出其词频；\n$$\nTF = \\frac{在某一条评论中单词w出现的次数}{该评论中去除stopword后的所有单词的数目}\n$$\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: nice B000F83SZQ+A1F6404F1VG29J   value: 0.10（词频）\n\n2.在获取该案例中评论的词频后，我们计算出每条评论中的词频-逆文件频率；\n$$\nTF - IDF_w = TF_w\\times lg\\frac{评论总数}{包含单词w的评论数}\n$$\n**输入：**nice B000F83SZQ+A1F6404F1VG29J    0.10（上一步骤中的输出） \n\n**输出：**nice B000F83SZQ+A1F6404F1VG29J    0.15 \n\n3.在得到每个评论中每个单词的词频-逆文件频率后，我们选取最高者，作为该评论的关键词；\n\n**输入：**nice B000F83SZQ+A1F6404F1VG29J    0.15 （上一步骤中的输出）\n\n**输出：** B000F83SZQ+A1F6404F1VG29J    nice \n\n4.在获取到每条评论的关键词后，根据该评论所评论的商品进行汇总，以降低文件大小，提高下一步骤中使用Python进行数据分析的效率；\n\n**输入：** B000F83SZQ+A1F6404F1VG29J    nice（上一步骤中的输出） \n\n**输出：** B000F83SZQ nice      5 \n\n5.根据前面计算出的不同商品的最终评分，利用Python对商品评论关键词的数目进行统计，得出不同评分区间下高频关键词的不同，进而分析评论内容对商品评分的影响。\n\n我们根据所得出的不同评分区间下关键词的个数，利用Python绘制成图云，如下所示：\n\n![img](/img/hadoop/level.jpg)\n\n从左到右、从上到下分布为商品评分在[1,2), [2,3), [3,4), [4,5)，[5,5]评论关键词的词云分布图。\n\n从图中，我们可以看出：\n\n•   因为一星评价的商品比较少，所以其评论数目也较少，且通过TF-IDF识别出来的关键字中多为姓名，不具有代表性；\n\n•   在二星、三星评价的商品中，多为waste、horrible、deleted等负面词语，与我们的认知相一致；\n\n•   在四星、五星评价的商品中，多为recipes、diet等食谱类的描述词语，可能食谱类书籍评分均较高；同时还存在着部分cute、Christmas、children、kids等词语，可能儿童类书籍评分较高。\n\n### **3.3**   **各个商品的基准平均评级**\n\n读入原始数据，以商品编号作为键，商品评级作为值，利用MapReduce计算每种商品的平均评级：\n\n**·参考代码****Overall.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: B000F83SZQ（商品编号）  value: 4.89（商品评级）\n\n得到每种商品的平均评级，部分示例如下：\n\nB000QCS8YM 5.0 \n\nB000QFOD8E 3.5 \n\nB000QUCOB2 4.285714 \n\nB000R3NNAE 4.4444447 \n\nB000R93D4Y 3.96 \n\nB000R93D8U 3.5 \n\n之后利用商品及其评级，统计各阶段评级的商品总数，商品最终评级视为评级整数部的数值大小：\n\n**·参考代码****CountOverall.java**\n\n**输入：**B000F83SZQ  4.89 \n\n**输出：**key: 1（商品等级）  value: 64（商品数量） \n\n利用Python统计出评级各阶段的商品总数目，并绘制成柱状图如下（Python代码：print_models.py）：\n\n![img](/img/hadoop/overallBase.png)\n\n| 评级     | 1    | 2    | 3     | 4     | 5    |\n| -------- | ---- | ---- | ----- | ----- | ---- |\n| 商品总数 | 64   | 823  | 10734 | 45596 | 4717 |\n\n从上图中可以看出，Kindle的各商品评级普遍较高，集中在4星左右，一星和二星的商品较少，存在一定数量的5星商品。\n\n## **4**    **商品评级修正**\n\n### **4.1**   **基于评论次数与整体评级的水军识别**\n\n1.利用之前写的统计不同日期评论数的代码，增加条件，筛选出评论数超过20条的记录。\n\n**·参考代码****CommentCountByDateOver20.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: 2000-03-05   value: 1 \n\n2.输入原始数据，计算每位评论者每天的评论总数，当一位评论者在一天之内评论总数超过一定数目α，或者评论总数占比当天评论总数超过某个阈值β，我们怀疑该评论者可能是职业刷评人员，最后用函数整理结果，得到这些人的评论ID。\n\n$$\n某人当天评论数 > \\alpha \\quad||\\quad\\frac{某人当天评论数}{当天评论总数} > \\beta\n$$\n**·参考代码****IsPaidPoster1.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: 2014-05-05,A1F6404F1VG29J   value: 20 \n\n设置α=15，β=0.25，得到潜在刷评人员60人，部分ID示例如下：\n\nA320TMDV6KCFU  A2YXNKWOGHP6AW   AAK9CEYIL2XL5   A9XRB71GIX26M AKE6711D72LTX  A1RXR105ND8OSH   A2AY83K9N60V38  A5IDWDZ2L1LA AAVZOTZWVQYRV  A1BSKHVCABJFXN 3FOL8CN5A1TFR\n\n3.输入原始数据，计算每位评论者所有评级的均值与方差，当一位评论者所有评级的均值大于4.9或小于1.1，并且所有评级的方差小于0.1，这些评论均视为恶评或好评，我们怀疑这些评论者可能是恶意刷评人员，即使不是，他们的评论也具有混淆产品评级的不当影响，我们将其等同于水军。最后用函数整理结果，只得到这些人的评论编号。为了加大该处理的可信度，我们只考虑了评论总数在100以上的评论者。\n\n$$\n\\begin{cases}\n某人所有评论评级的均值>4.9\\quad ||\\quad某人所有评论评级的均值<0.1 \\\\\n某人所有评论评级的方差 < 0.1 \\\\\n某人所有评论评级的数目 > 100\n\\end{cases}\n$$\n**·参考代码****IsPaidPoster2.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: A12E0W3IY6RJM   value: 4.9606986  0.037756715 \n\n最终得到潜在恶评人员144位，他们的部分ID如下：\n\nA107QCQSFVT6VN    A10C4X94VN9IG8    A1141DEY00149Z    A12E0W3IY6RJMA12NCJPL1Y3AH4    A13D5S4OXQUPRM    A141H51I3H4B1S A17YQQLSTXODGV A18L0QYPXCUD8E    A18YWXFF8FFGB2    A19BBQS3X97H2B\n\n将两种处理方式汇总，我们得到了199位潜在评论不当用户，其中5位兼具刷评与恶意评论两条性质，他们的ID以及昵称如下：\n\n| ID             | 昵称           |\n| -------------- | -------------- |\n| A1ENV91MFAEVA3 | JoT            |\n| A24F8TZ7WU4JDQ | Rebecca Palmer |\n| A28MPK002D2WJ1 | AA             |\n| A3M7QUA7XT7XIM | Jr.            |\n| A3PTWPKPXOG8Y5 | Alexis         |\n\n利用之前写的统计每种商品的平均评级的代码Overall.java，增加条件，剔除水军的评论，确保每条评论的有效性。得到新的每种商品的评论评级。\n\n**·参考代码****OverallClean.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: B000F83SZQ（商品编号）  value: 4.25（商品评级）\n\n利用商品及其评级，重新统计各阶段评级的商品总数，商品评级整数部的数值大小视为最终评级。\n\n| 评级     | 1    | 2    | 3     | 4     | 5    |\n| -------- | ---- | ---- | ----- | ----- | ---- |\n| 商品总数 | 70   | 872  | 11056 | 45033 | 4902 |\n\n我们发现经过处理，商品总数减少了1个，对应的事实便是，少了的商品的全部评论均由水军带来，或者说均是我们认定的无效评论。该商品的AsinID及平均评级为：\n\nB00IT2GHAS 5.0\n\n截止2018年12月，该商品具体信息如下：\n\n![img](/img/hadoop/gay.png)\n\n可以发现，现阶段该商品增加了许多1星评论，而且它的评级呈现5星和1星的两极化趋势，所以，该商品很可能符合我们的猜想，全部评论均由水军带来，存在不实评价的情况。\n\n### **4.2**   **基于评论时效性及帮助度的评分修正**\n\n依据评论的帮助评分与评论时间，赋予每个评级不同帮助度与时效性的权重，重新计算剔除水军后的商品评级。\n\n输入原始数据，利用之前写的统计剔除水军后的每种商品的平均评级的代码OverallClean.java，融入每条评论评级权重信息，重新计算每种商品评级。参考参数helpful及unixReviewTime，计算每条评论的帮助度以及时效性。\n\n【帮助度】当一条评论没有帮助度时，我们将本条关于该商品的评论设为所有其他有帮助度的均值，平均其重要度。取值区间为(0, 1]；\n\n【时效性】我们用评论时间戳比上最新的2014-7-23，即unixTime=1406073600的结果再平方（以增加区别度），当做时效性的参数。取值区间为(0, 1]；\n\n$$\n\\begin{cases}\n针对同一商品，每条评论评级的得分为ax_i + by_i \\\\\n针对同一商品，每条评论评级的权重为\\frac{ax_i + by_i}{(ax_1 + by_1 + \\cdots + ax_n + by_n)}\n\\end{cases}\\\\\n其中，帮助度为x,时效性为y\n$$\n设置帮助度系数a=1，时效性系数为b=1，即，我们认为帮助度与时效性同等重要。\n\n**·参考代码****OverallWeights.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: B000F83SZQ（商品编号）  value: 4.249840640960779（商品评级）\n\n利用商品及其评级，重新统计各阶段评级的商品总数，商品评级整数部的数值大小视为最终评级。\n\n| 评级     | 1    | 2    | 3     | 4     | 5    |\n| -------- | ---- | ---- | ----- | ----- | ---- |\n| 商品总数 | 88   | 1086 | 12775 | 43082 | 4902 |\n\n利用Python绘制成折线图，对比三阶段的商品评级统计结果。\n\n首先是各阶段评级商品总数（Python代码：print_zhe.py）：\n\n![img](/img/hadoop/overall.png)\n\n| 评级           | 1    | 2    | 3     | 4     | 5    |\n| -------------- | ---- | ---- | ----- | ----- | ---- |\n| overall        | 64   | 823  | 10724 | 45596 | 4717 |\n| overallClean   | 70   | 872  | 11056 | 45033 | 4902 |\n| overallWeights | 88   | 1086 | 12775 | 43082 | 4902 |\n\n经过不断的调整，四星级商品数在逐渐下滑到三星级，一星级、二星级商品数也有微量增多，我们的评级系统变得越来越严格。\n\n同时，我们观察到评级为5的商品数目在剔除水军后增加了一部分，我们分析可能是有竞争对手恶意刷评导致评分下降。然而进行了权重修改后评级为5的商品数目没有改动，这是因为评级为5的商品必须符合每条评论均为5星，这样，无论我们如何修改权重，都无法改变商品的评级。\n\n另外，我们认为评论数与销售量在一定程度上成正比，所以我们将平均评论量类比为商品受欢迎程度，以下是各阶段商品的平均评论条数（保留两位小数）。\n\n**·参考代码****AvgReview.java**\n\n![img](/img/hadoop/overallAvgReview.png)\n\n| 评级           | 1    | 2    | 3     | 4     | 5    |\n| -------------- | ---- | ---- | ----- | ----- | ---- |\n| overall        | 7.06 | 9.54 | 14.64 | 16.54 | 6.62 |\n| overallClean   | 7.07 | 9.53 | 14.54 | 16.63 | 6.58 |\n| overallWeights | 6.91 | 8.91 | 13.83 | 16.98 | 6.58 |\n\n整体上分析我们发现，1~4级评级递增时，平均评论量也是依次递增的，符合了我们的假设，即评论数与销售量在一定程度上成正比。反观5星评级的商品却又有最低的评论量，我们猜测5星评级商品会更少有争议，少了大量的吐槽评论，购买者意见较为一致，会更多的选择点赞帮助评分，而不是自行评价，同时会有更多的回购用户，而回购用户往往不会进行二次评价。\n\n​    分开来看三条折线，经过不断的调整，1~4星的平均评论量递增曲线变得愈加陡峭，具体表现为评级为1~3的商品平均评论量均在不断下降，而评级为4的商品平均评论量在不断上升。评级不同，商品平均评论量的差距也在拉大。\n\n### **4.3**   **基于**CoreNLP的评论情感识别\n\n正如我们前面的发现，评级为5的商品是无论如何都不会再被降级的，那么对于那些商品普通，评论很少，评论里描述平平的，就因为仅有的几条评论就能保持5星的情况，显然是不符合实际的。这些评级本身就十分不严谨，外加已经存在评级为5星的商品却拥有最低的商品平均评论量的现状，我们意识到了每条评论的星级本身也需要具有准确性。\n\n我们还发现，每个人的评论标准都不大相同，有的人要求严格，评分整体偏低，有的人比较随意，评分忽高忽低，所以，我们有必要给出科学的评级方式，再结合原本的评级，对每条评论本身的星级进行修改。\n\n情感分析是指利用机器提取人们对某人或事物的态度，从而发现潜在的问题用于改进或预测。商品的评价分为星级评价和文本评价。星级评价和好评率在排序算法中占据重要地位。有的商家为了提升排名，采取“五星好评返现”的方式来诱导顾客好评，但实际上用户可能对商品并不满意，因此会在文本评论或者追加评论时说出对商品不满意的真实评价。因此，对评论文本进行情感分析并使用文本评论好评率来对商品进行重新排序，指导人们根据真实评价选取商品就很显得有意义。本文中，利用CoreNLP包对商品评论进行情感分析，以对商品评分进行矫正。\n\n为简化模型，我们做出如下假设：\n\n• 评论中长度最长的一句话代表该评论的情感；\n\n由于，该模型较为复杂，需要运行较长的时间，我们仅运行前1000条的评论数据。\n\n**·参考代码****SentimentAnalysis.java**\n\n**输入：**{\"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage ... for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"} \n\n**输出：**key: B000F83SZQ+A1F6404F1VG29J   value: 2 \n\n输出的value值表示评论的正负面情绪，其中，1~5分别代表极度负面、负面、中性、正面、极度正面）\n\n列出矫正示例如下：\n\n| 商品编号   | 评论者ID      | 原评级 | 矫正评级 |\n| ---------- | ------------- | ------ | -------- |\n| B000FA64PA | AQZH7YTWQPOBE | 4      | 2        |\n\n内容：This is a short story focused on Darth Maul's role in helping the Trade Federation gain a mining colony. It's not bad, but it's also nothing exceptional. It's fairly short so we don't really get to see any characters develop. The few events that do happen seem to go by quickly, including what should have been major battles. The story is included in the novelShadow Hunter (Star Wars: Darth Maul), which is worth reading, so don't bother to buy this one separately.\n\n| 商品编号   | 评论者ID      | 原评级 | 矫正评级 |\n| ---------- | ------------- | ------ | -------- |\n| B000FA64PK | A2QK1U70OJ74P | 5      | 5        |\n\n内容：Excellent! Very well written story, very exciting with LOTS of action. The bad guys trying to kill Leia and Han. Viki Shesh is introduced.\n\n### **4.4**   **基于时效性、帮助性、情感识别的书籍评分修正**\n\n依据情感分析得到的矫正评级，以及原评级，综合之前的纠正方法，重新计算情绪分析1000条数据的商品评级。\n\n**·参考代码****OverallSentiment.java**\n\n得到新的对比数据：各评级商品数目、各评级平均评论量，结果如下：\n\n| 1000条数据处理结果 | 1    | 2    | 3     | 4     | 5    |\n| ------------------ | ---- | ---- | ----- | ----- | ---- |\n| 原（商品数目）     |      | 1    | 37    | 50    | 5    |\n| 矫正（商品数目）   |      | 10   | 75    | 8     |      |\n| 原（平均评论量）   |      | 15.0 | 9.51  | 11.66 | 5.6  |\n| 矫正（平均评论量） |      | 10.4 | 10.96 | 6.5   |      |\n\n由于数据量较少，整体分析我们发现针对原本的处理结果，商品数目是比较吻合之前的所有数据处理结果的趋势的，即商品数目集中处于4等评级左右，但是平均评论量就与之前的趋势不符，我们认为这可能是数据量少，导致数据采集不够随机而出现的偏差，所以平均评论量的测量并不能反映样本代表总体的结果，商品数目便成为了我们分析的重点。\n\n首先，我们看到情绪分析的结果对评级结果有十分大的改动。情绪分析后评级总体呈下降趋势，许多4星商品变成了3星商品，5星商品甚至完全消失，而2级商品仅有增加却没有下降，最终商品数目的数据集中点变成了3等评级。我们认为情绪分析的结果评级为5或1是鲜少的，即评论内容想要达到极度正面或极度负面是十分困难的，所以情绪分析的结果符合我们对偏好差异的修正，结果贴合现实中极少出现一致好评或一致恶评的判断情形，呈现比较中等客观的评分情形。\n\n### **4.5**   **部分得分较高电子书列表**\n\nB000QCS8YM\n\n![img](/img/hadoop/1.png)\n\nB000UH5Z3A\n\n![img](/img/hadoop/2.png)\n\nB002F0826C\n\n![img](/img/hadoop/3.png)\n\nB002RHP5TK\n\n![img](/img/hadoop/4.png)\n\n更多更好的书单请关注我们的输出结果中的OverallWeights\n\n## **5**    **总结和展望**\n\n### **5.1**    **问题及总结**\n\n问题：缺乏相对准确的客观评分，无法通过最小二乘法等估计出相对准确的各参数取值；\n\n问题：情绪分析的模型较为复杂，导致运算速度较慢，无法对全部数据进行分析，且情绪分析结果存在误差；\n\n问题：数据与当下的时间脱轨，未能完全反应当下的需求。\n\n总结：我们的项目实现了商品评论的修正，得到了相对真实的评论情况。由于缺乏相对准确的评分、及时的数据、简单有效的模型，所以导致我们的评分修正模型仍存在一定的误差。\n\n### **5.2**   **展望**\n\n· 通过人工对Kindle产品进行判断，得出相对准确的客观评分，从而通过最小二乘估计等办法，得出相对准确的参数估计值；\n\n· 优化情感分析算法，使之可以在更多的时间内能够处理更多的数据，且判断更加准确；\n\n· 搜集最近的数据，用以验证我们的评分修正模型的准确性；\n\n· 考虑用户之间的联系，通过网络自回归模型，对评分模型进行进一步的修正等。\n\n \n\n ","tags":["专业课"]},{"title":"Markdown公式合集","url":"/2019/04/Markdown公式合集/","content":"\n## 常用公式符号\n\n### 角标\n\n\"_\"—>down\n\n\"^\"—>up\n\n```\nx_1 \\\\\\\\\n\nx_1^2 \\\\\\\\\n\nx^2_1 \\\\\n\nx_{22}^{(n)} \\\\\n\n^*x^* \\\\\n\nx_{down}^{up}\n```\n\n\n$$\nx_1 \\\\\\\\\n\nx_1^2 \\\\\\\\\n\nx^2_1 \\\\\n\nx_{22}^{(n)} \\\\\n\n^*x^* \\\\\n\nx_{down}^{up}\n$$\n\n### 分号\n\nfrac\n\n```\n\\frac{x+y}{2} \\\\\n\n\\frac{1}{1+\\frac{1}{2}}\n```\n\n\n$$\n\\frac{x+y}{2} \\\\\n\n\\frac{1}{1+\\frac{1}{2}}\n$$\n\n### 根号\n\nsqrt\n\n第二和第三个的区别在于为了美观微调位置 ^_^\n\n```\n\\sqrt{2}<\\sqrt[3]{3} \\\\\n\n\\sqrt{1+\\sqrt[p]{1+a^2}} \\\\\n\n\\sqrt{1+\\sqrt[^p\\!]{1+a^2}}\n```\n\n\n$$\n\\sqrt{2}<\\sqrt[3]{3} \\\\\n\n\\sqrt{1+\\sqrt[p]{1+a^2}} \\\\\n\n\\sqrt{1+\\sqrt[^p\\!]{1+a^2}}\n$$\n\n### 求和、积分\n\nsum\n\nint\n\n```\n\\sum_{k=1}^{n}\\frac{1}{k} \\\\\n\n\\int_a^b f(x)dx \\\\\n\n\\int_a^b f(x)\\mathrm{d}x\n```\n\n$$\n\\sum_{k=1}^{n}\\frac{1}{k} \\\\\n\n\\int_a^b f(x)dx \\\\\n\n\\int_a^b f(x)\\mathrm{d}x\n$$\n\n### 空格\n\n```\n紧贴 a\\!b \\\\\n没有空格 ab \\\\\n小空格 a\\,b \\\\\n中等空格 a\\;b \\\\\n大空格 a\\ b \\\\\nquad空格 a\\quad b \\\\\n两个quad空格 a\\qquad b \\\\\n```\n\n\n$$\n紧贴 a\\!b \\\\\n没有空格 ab \\\\\n小空格 a\\,b \\\\\n中等空格 a\\;b \\\\\n大空格 a\\ b \\\\\nquad空格 a\\quad b \\\\\n两个quad空格 a\\qquad b \\\\\n$$\n\n### 括号\n\n```\n\\left(\\sum_{k=\\frac{1}{2}}^{N^2}\\frac{1}{k}\\right) \\\\\n(\\sum_{k=\\frac{1}{2}}^{N^2}\\frac{1}{k})\n```\n\n\n$$\n\\left(\\sum_{k=\\frac{1}{2}}^{N^2}\\frac{1}{k}\\right) \\\\\n(\\sum_{k=\\frac{1}{2}}^{N^2}\\frac{1}{k})\n$$\n\n### 矩阵\n\n```\n\\begin{matrix}1&2\\\\3&4\\end{matrix} \\\\\n\n\\begin{pmatrix}1 & 2\\\\\\\\3 &4\\end{pmatrix} \\\\\n\n\\begin{bmatrix}1 & 2\\\\\\\\3 &4\\end{bmatrix} \\\\\n\n\\begin{Bmatrix}1 & 2\\\\\\\\3 &4\\end{Bmatrix} \\\\\n\n\\begin{vmatrix}1 & 2\\\\\\\\3 &4\\end{vmatrix} \\\\\n\n\\left|\\begin{matrix}1 & 2\\\\\\\\3 &4\\end{matrix}\\right| \\\\\n\n\\begin{Vmatrix}1 & 2\\\\\\\\3 &4\\end{Vmatrix}\n```\n\n\n$$\n\\begin{matrix}1&2\\\\3&4\\end{matrix} \\\\\n\n\\begin{pmatrix}1 & 2\\\\\\\\3 &4\\end{pmatrix} \\\\\n\n\\begin{bmatrix}1 & 2\\\\\\\\3 &4\\end{bmatrix} \\\\\n\n\\begin{Bmatrix}1 & 2\\\\\\\\3 &4\\end{Bmatrix} \\\\\n\n\\begin{vmatrix}1 & 2\\\\\\\\3 &4\\end{vmatrix} \\\\\n\n\\left|\\begin{matrix}1 & 2\\\\\\\\3 &4\\end{matrix}\\right| \\\\\n\n\\begin{Vmatrix}1 & 2\\\\\\\\3 &4\\end{Vmatrix}\n$$\n\n```\n\\mathbf{X} =\n\\left( \\begin{array}{ccc}\nx_{11} & x\\_{12} & \\ldots \\\\\\\\\nx\\_{21} & x\\_{22} & \\ldots \\\\\\\\\n\\vdots & \\vdots & \\ddots\n\\end{array} \\right)\n```\n\n\n$$\n\\mathbf{X} =\n\\left( \\begin{array}{ccc}\nx_{11} & x\\_{12} & \\ldots \\\\\\\\\nx\\_{21} & x\\_{22} & \\ldots \\\\\\\\\n\\vdots & \\vdots & \\ddots\n\\end{array} \\right)\n$$\n\n### 长公式\n\n```\n不对齐\\\\\n\\begin{multline}\nx = a+b+c+{} \\\\\\\\\nd+e+f+g\n\\end{multline}\n\\\\对齐\\\\\n\\begin{aligned}\nx ={}& a+b+c+{} \\\\\\\\\n&d+e+f+g\n\\end{aligned}\n```\n\n\n$$\n不对齐\\\\\n\\begin{multline}\nx = a+b+c+{} \\\\\\\\\nd+e+f+g\n\\end{multline}\n\\\\对齐\\\\\n\\begin{aligned}\nx ={}& a+b+c+{} \\\\\\\\\n&d+e+f+g\n\\end{aligned}\n$$\n\n### 公式组\n\n居中\n\n```\n\\begin{gather}\na = b+c+d \\\\\nx = y+z\n\\end{gather}\n```\n\n\n$$\n\\begin{gather}\na = b+c+d \\\\\nx = y+z\n\\end{gather}\n$$\n对齐\n\n```\n\\begin{align}\na &= b+c+d \\\\\nx &= y+z\n\\end{align}\n```\n\n\n$$\n\\begin{align}\na &= b+c+d \\\\\nx &= y+z\n\\end{align}\n$$\n\n### 分段函数\n\n```\ny=\\begin{cases}\n-x,\\quad x\\leq 0 \\\\\\\\\nx,\\quad x>0\n\\end{cases}\n```\n\n\n$$\ny=\\begin{cases}\n-x,\\quad x\\leq 0 \\\\\\\\\nx,\\quad x>0\n\\end{cases}\n$$\n\n### 划线、制表\n\n```\n\\left(\\begin{array}{|c|c|}\n1 & 2 \\\\\n\\hline\n3 & 4\n\\end{array}\\right) \\\\\n\n\\begin{array}{|c|c|}\n\\hline11 & \\cdots \\\\\n\\hline3 & 4 \\\\\n\\hline\n\\end{array}\n```\n\n\n$$\n\\left(\\begin{array}{|c|c|}\n1 & 2 \\\\\n\\hline\n3 & 4\n\\end{array}\\right) \\\\\n\n\\begin{array}{|c|c|}\n\\hline\n11 & \\cdots \\\\\n\\hline\n3 & 4 \\\\\n\\hline\n\\end{array}\n$$\n\n### 希腊字母\n\n```\n\\begin{array}{|c|c|c|c|c|c|c|c|}\n\\hline\n{\\alpha} & {\\backslash alpha} & {\\theta} & {\\backslash theta} & {o} & {o} & {\\upsilon} & {\\backslash upsilon} \\\\\\\\\n\\hline\n{\\beta} & {\\backslash beta} & {\\vartheta} & {\\backslash vartheta} & {\\pi} & {\\backslash pi} & {\\phi} & {\\backslash phi} \\\\\\\\\n\\hline\n{\\gamma} & {\\backslash gamma} & {\\iota} & {\\backslash iota} & {\\varpi} & {\\backslash varpi} & {\\varphi} & {\\backslash varphi} \\\\\\\\\n\\hline\n{\\delta} & {\\backslash delta} & {\\kappa} & {\\backslash kappa} & {\\rho} & {\\backslash rho} & {\\chi} & {\\backslash chi} \\\\\\\\\n\\hline\n{\\epsilon} & {\\backslash epsilon} & {\\lambda} & {\\backslash lambda} & {\\varrho} & {\\backslash varrho} & {\\psi} & {\\backslash psi} \\\\\\\\\n\\hline\n{\\varepsilon} & {\\backslash varepsilon} & {\\mu} & {\\backslash mu} & {\\sigma} & {\\backslash sigma} & {\\omega} & {\\backslash omega} \\\\\\\\\n\\hline\n{\\zeta} & {\\backslash zeta} & {\\nu} & {\\backslash nu} & {\\varsigma} & {\\backslash varsigma} & {} & {} \\\\\\\\\n\\hline\n{\\eta} & {\\backslash eta} & {\\xi} & {\\backslash xi} & {\\tau} & {\\backslash tau} & {} & {} \\\\\\\\\n\\hline\n{\\Gamma} & {\\backslash Gamma} & {\\Lambda} & {\\backslash Lambda} & {\\Sigma} & {\\backslash Sigma} & {\\Psi} & {\\backslash Psi} \\\\\\\\\n\\hline\n{\\Delta} & {\\backslash Delta} & {\\Xi} & {\\backslash Xi} & {\\Upsilon} & {\\backslash Upsilon} & {\\Omega} & {\\backslash Omega} \\\\\\\\\n\\hline\n{\\Omega} & {\\backslash Omega} & {\\Pi} & {\\backslash Pi} & {\\Phi} & {\\backslash Phi} & {} & {} \\\\\\\\\n\\hline\n\\end{array}\n```\n\n\n$$\n\\begin{array}{|c|c|c|c|c|c|c|c|}\n\\hline\n{\\alpha} & {\\backslash alpha} & {\\theta} & {\\backslash theta} & {o} & {o} & {\\upsilon} & {\\backslash upsilon} \\\\\\\\\n\\hline\n{\\beta} & {\\backslash beta} & {\\vartheta} & {\\backslash vartheta} & {\\pi} & {\\backslash pi} & {\\phi} & {\\backslash phi} \\\\\\\\\n\\hline\n{\\gamma} & {\\backslash gamma} & {\\iota} & {\\backslash iota} & {\\varpi} & {\\backslash varpi} & {\\varphi} & {\\backslash varphi} \\\\\\\\\n\\hline\n{\\delta} & {\\backslash delta} & {\\kappa} & {\\backslash kappa} & {\\rho} & {\\backslash rho} & {\\chi} & {\\backslash chi} \\\\\\\\\n\\hline\n{\\epsilon} & {\\backslash epsilon} & {\\lambda} & {\\backslash lambda} & {\\varrho} & {\\backslash varrho} & {\\psi} & {\\backslash psi} \\\\\\\\\n\\hline\n{\\varepsilon} & {\\backslash varepsilon} & {\\mu} & {\\backslash mu} & {\\sigma} & {\\backslash sigma} & {\\omega} & {\\backslash omega} \\\\\\\\\n\\hline\n{\\zeta} & {\\backslash zeta} & {\\nu} & {\\backslash nu} & {\\varsigma} & {\\backslash varsigma} & {} & {} \\\\\\\\\n\\hline\n{\\eta} & {\\backslash eta} & {\\xi} & {\\backslash xi} & {\\tau} & {\\backslash tau} & {} & {} \\\\\\\\\n\\hline\n{\\Gamma} & {\\backslash Gamma} & {\\Lambda} & {\\backslash Lambda} & {\\Sigma} & {\\backslash Sigma} & {\\Psi} & {\\backslash Psi} \\\\\\\\\n\\hline\n{\\Delta} & {\\backslash Delta} & {\\Xi} & {\\backslash Xi} & {\\Upsilon} & {\\backslash Upsilon} & {\\Omega} & {\\backslash Omega} \\\\\\\\\n\\hline\n{\\Omega} & {\\backslash Omega} & {\\Pi} & {\\backslash Pi} & {\\Phi} & {\\backslash Phi} & {} & {} \\\\\\\\\n\\hline\n\\end{array}\n$$\n\n","tags":["学习笔记"]},{"title":"Hexo","url":"/2019/04/Hexo/","content":"\n# hexo学习\n\n## 主文件夹下\n\n**_config.yml**\n\n网站的配置信息，您可以在此配置大部分的参数。\n\n**package.json**\n\n应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。\n\n**scaffolds**\n\n模版。当您新建文章时，Hexo 会根据 scaffold 来建立文件。\n\nHexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。\n\n**source**\n\n资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。\n\n**themes**\n\n主题文件夹。Hexo 会根据主题来生成静态页面。\n\n## 新建一个文档\n\n```\nhexo new [layout]<title>` # 如果标题包含空格的话，请使用引号括起来\nhexo new \"post title with whitespace\"\n\nhexo generate # 生成静态文件\n\nhexo -d # deploy文件生成后立即部署网站\nhexo -w # watch监视文件变动\n\nhexo server # 启动服务器，在本地查看\n\nhexo clean # 清除缓存文件 (db.json) 和已生成的静态文件 (public）\n\n\n```\n\n## 页脚设置\n\n```\nfooter:\n  copyright: \n  powered:\n    # Hexo link (Powered by Hexo).\n    enable: false\n  theme:\n    enable: true\n  beian:\n    enable: false\n    icp:\n```\n\n","tags":["学习笔记"]}]