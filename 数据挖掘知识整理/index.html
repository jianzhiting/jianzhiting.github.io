<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="2333333333">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        数据挖掘知识整理 - JiZiTi | 学习管理
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <link href="//at.alicdn.com/t/font_1165120_w77ne6oe34j.css" rel="stylesheet" type="text/css">
    <!-- https://www.bootcdn.cn/mathjax/ -->
    
    <script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> to be better </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar">
            <img src="/img/avatar.jpg">
        </div>
        <div class="name">
            <i>JiZiTi</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li>
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li>
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#概述"><span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据探查与预处理"><span class="toc-text">数据探查与预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#探查数据集特征"><span class="toc-text">探查数据集特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#探查数据质量"><span class="toc-text">探查数据质量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#探查属性特征"><span class="toc-text">探查属性特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据清洗"><span class="toc-text">数据清洗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据集成"><span class="toc-text">数据集成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据消减"><span class="toc-text">数据消减</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据转换"><span class="toc-text">数据转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#复杂数据类型的预处理：特征提取"><span class="toc-text">复杂数据类型的预处理：特征提取</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多元线性回归"><span class="toc-text">多元线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#多元线性回归方程的形式和假定"><span class="toc-text">多元线性回归方程的形式和假定</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方差分析与回归目标"><span class="toc-text">方差分析与回归目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#回归参数求解"><span class="toc-text">回归参数求解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型评估与误差来源分析"><span class="toc-text">模型评估与误差来源分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#回归方程选择与正则化"><span class="toc-text">回归方程选择与正则化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#逻辑回归"><span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树"><span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#贝叶斯-k近邻-SVM"><span class="toc-text">贝叶斯-k近邻-SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分类器的评估与不平衡分布类"><span class="toc-text">分类器的评估与不平衡分布类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#决策阈值"><span class="toc-text">决策阈值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类器的评估指标"><span class="toc-text">分类器的评估指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#评估方法（验证集的划分方法）"><span class="toc-text">评估方法（验证集的划分方法）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#辅助图形"><span class="toc-text">辅助图形</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#不平衡分布类处理技术"><span class="toc-text">不平衡分布类处理技术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络"><span class="toc-text">神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#感知器模型"><span class="toc-text">感知器模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BP算法"><span class="toc-text">BP算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度学习"><span class="toc-text">深度学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#神经网络方法特点"><span class="toc-text">神经网络方法特点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组合分类与多分类"><span class="toc-text">组合分类与多分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#聚类分析"><span class="toc-text">聚类分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#聚类分析思想"><span class="toc-text">聚类分析思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#主要聚类方法"><span class="toc-text">主要聚类方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他"><span class="toc-text">其他</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input">
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i> to be better </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        数据挖掘知识整理
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-04-28 08:54:09</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#专业课" title="专业课">专业课</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>

    </div>
    <div class="post-content no-indent">
        <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>简单地说，数据挖掘就是从大量数据中自动发现或“挖掘”隐藏在数据背后的有用信息的过程，数据挖掘分类如下：</p>
<ol>
<li>按照数据集中是否已知目标变量的取值：<ul>
<li>预测性挖掘任务(有监督学习)<br>根据某些属性的值预测特定属性的值，往往用于对新数据的预测.<br>被预测的属性一般称为目标变量(或因变量)，用来预测的变量称为输入变量(或自变量，说明变量)</li>
<li>描述性挖掘任务(无监督学习)<br>描述数据的特征<br>降维与可视化(数据预处理)<br>聚类分析<br>关联分析<br>孤立点检测</li>
</ul>
</li>
<li>按照学习结果能否实时动态更新和应用，也是训练数据的方法<ul>
<li>批量挖掘(线下学习)<br>先从历史数据集学习，再将学习结果应用于新数据.如果历史数据有更新，则需要重新学习.学习费事耗资源.</li>
<li>增量学习(在线学习)<br>从顺序输入的单个或小批量数据集不断学习，每次学习都廉价快速.适用于从不断变化的数据中学习，或历史数据集太大不能全部放入内存的情况.</li>
</ul>
</li>
<li>按照学习方式的不同<ul>
<li>基于模型的学习(理性主义)</li>
<li>基于实例的学习(经验主义)</li>
</ul>
</li>
<li>按照目标变量的类型<ul>
<li>回归(连续)<br>线性回归与多项式回归<br>分类与回归树<br>SVR<br>神经网络<br>K近邻  …</li>
<li>分类(离散)<br>逻辑回归<br>SVM<br>决策树与随机森林<br>神经网络<br>贝叶斯<br>K近邻 …</li>
</ul>
</li>
</ol>
<h2 id="数据探查与预处理"><a href="#数据探查与预处理" class="headerlink" title="数据探查与预处理"></a>数据探查与预处理</h2><script type="math/tex; mode=display">
数据集\begin{cases}
    训练集 \begin{cases}
    训练集：构建模型
    \\
    验证集：选择和调整模型
    \end{cases}
\\\\
测试集：评估模型在新数据上的预测能力
\end{cases}</script><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">数据集的一行</th>
<th style="text-align:center">数据集的某列</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">数据对象</td>
<td style="text-align:center">属性</td>
</tr>
<tr>
<td style="text-align:center">实例</td>
<td style="text-align:center">变量</td>
</tr>
<tr>
<td style="text-align:center">记录</td>
<td style="text-align:center">维</td>
</tr>
<tr>
<td style="text-align:center">观测</td>
<td style="text-align:center">特征</td>
</tr>
</tbody>
</table>
</div>
<p>数据探查的目的是：评估数据质量，发现数据问题、理解数据、为数据预处理提供依据和思路.</p>
<h3 id="探查数据集特征"><a href="#探查数据集特征" class="headerlink" title="探查数据集特征"></a>探查数据集特征</h3><ol>
<li>数据的集成程度</li>
<li>数据的规模</li>
<li>数据是否具有稀疏性</li>
</ol>
<h3 id="探查数据质量"><a href="#探查数据质量" class="headerlink" title="探查数据质量"></a>探查数据质量</h3><ol>
<li>数据的可用性<br> 属性含义、类型、取值单位、范围及约束说明</li>
<li>数据对应用的适合性<br> 相关性、完备性、时效性</li>
<li>数据的代表性(抽样偏倚)</li>
<li>数据收集问题<br> 数据的重复、缺失、不一致问题</li>
</ol>
<h3 id="探查属性特征"><a href="#探查属性特征" class="headerlink" title="探查属性特征"></a>探查属性特征</h3><ol>
<li><p>属性的含义、取值单位（粒度）</p>
</li>
<li><p>属性类型与测量水平</p>
<p><img src="../img/loading.gif" data-original="\img\datamining\var.png" alt="属性类型"><br>区间：没有绝对零值（即当变量值为0时不是表示没有，如温度变量，当温度为0时，并不是表示没有温度）<br>比率：有绝对零值，两个数的倍数是有意义的</p>
</li>
<li><p>是否存在缺失值</p>
</li>
<li><p>描述性统计指标<br> 数值型属性也可以取字符型属性的测量水平</p>
<ul>
<li>属性取值的中心趋势<br>数值属性：均值、截尾均值、三均值<br>字符属性：众数</li>
<li>属性取值的离散程度<br>数值属性：极差、方差、标准差、平均绝对偏差、四分位数、四分位极差、变异系数<br>字符属性：取值个数</li>
<li>极端值的识别<br>根据极值和常识判断<br>根据上下截断点<br>正态分布的3σ原则</li>
<li>分布的对称性与中心集中度<br><img src="../img/loading.gif" data-original="/img/datamining/paindu.png" style="width:80%"><br><img src="../img/loading.gif" data-original="/img/datamining/fengdu.png" style="width:80%"></li>
<li>属性间取值的相关性<br>数值型变量：<a href="https://www.zhihu.com/question/19734616" target="_blank" rel="noopener">Pearson相关系数</a>、夹角余弦；spearman相关系数、kendall相关系数Tau-b、Hoeffding相关系数<br>名义变量：<script type="math/tex">{\chi}^2</script>检验<br>名义变量与数值变量之间：数值型变量离散化、统计方法（如T检验，Z检验，方差分析）</li>
</ul>
</li>
<li><p>数据的图形表示</p>
<p>安斯库姆四重奏<br><img src="../img/loading.gif" data-original="/img/datamining/ansi.png" style="width: 80%"><br><img src="../img/loading.gif" data-original="/img/datamining/kumu.png" style="width: 40%"></p>
<p>分位数图、直方图(数值型数据)或柱形图(字符型数据)、盒形图、茎叶图、饼图、散点图、折线图</p>
</li>
</ol>
<hr>

<p>数据预处理的目的：减少噪声、不完整和不一致数据，可以提高模型的质量，进而提高数据挖掘的有效性和准确性。（一个挖掘项目中需要的数据预处理与初始数据的质量、采用的分析方法、分析目标都有关系）</p>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><ol>
<li>处理错误或不一致的数据</li>
<li><p>处理缺失值</p>
<ul>
<li>数据缺少的主要原因<br>数据不可得或获取成本太大<br>输入遗漏，理解错误，或传输错误等<br>属性值不存在（例如未婚者的配偶）</li>
<li>处理<br>不做处理<br>删除该条记录<br>增加标识变量<br>填补<ul>
<li>人工确定值或固定值</li>
<li>均值（中位数）或众数</li>
<li>同类别的均值（中位数）或众数</li>
<li>预测值：利用分类预测技术推断出最大可能取值</li>
</ul>
</li>
</ul>
</li>
<li><p>识别处理孤立点</p>
<ul>
<li>识别<br>常识<br>统计规则<br>(盒图中上下超过1.5倍箱体长度以外的点；正太分布均值的3个标准差之外的点)<br>聚类，…</li>
<li>处理<br>去除<br>视为噪声，进行平滑，盖帽法<br>保留</li>
</ul>
</li>
<li><p>平滑噪声数据<br> 噪声：变量取值存在的随机误差、不可理解的取值、错误、极端值</p>
<ul>
<li><p>分箱<br>排序→确定相数→确定每箱数据个数/确定箱距→分配→替换<br>分箱方法利用数据的“近邻”(即周围的值)来平滑一组有序数据的值。首先对数据进行排序，并分配到具有相同高度(每箱数据项个数相同)或宽度(等距)的不同的“箱”中；其次通过箱子的平均值(Means)、中值(Median)、或者边界值等来进行平滑处理。一种观点：通过分箱个数(分箱后为有序变量)量化变量的权重</p>
<p>等高分箱：每箱数据个数相同<br>等宽分箱：每箱的箱距相同</p>
</li>
<li><p>聚类<br>聚类后找出孤立点，确定其存在的噪声属性，修改该属性值</p>
</li>
<li><p>回归</p>
</li>
</ul>
</li>
</ol>
<h3 id="数据集成"><a href="#数据集成" class="headerlink" title="数据集成"></a>数据集成</h3><ol>
<li>合并多个数据源中的数据，将之存放在一个一致的数据存储中<ul>
<li>模式集成问题 ：同名不同义，同义不同名。</li>
<li>数据值冲突的检测与处理<br>例如：不同的计量单位、取值层次</li>
<li>数据冗余问题</li>
</ul>
</li>
<li>纵向集成和横向集成</li>
</ol>
<h3 id="数据消减"><a href="#数据消减" class="headerlink" title="数据消减"></a>数据消减</h3><p>数据消减(data reduction)的目的就是缩小所挖掘数据的规模，但却不会影响(或基本不影响)最终的挖掘结果。Aggregation(聚合)：例如：汇总数据代替明细数据，注意汇总的粒度；</p>
<ol>
<li><p>维归约</p>
<ul>
<li><p>属性构造<br>汇总属性的粒度<br>(例如：电话流失客户分月通话分钟数、电话流失客户分天通话分钟数)</p>
</li>
<li><p>数据压缩（PCA、奇异值分解、小波变换等）<br>数据压缩是使用数据编码或变换，以便得到原数据的“压缩”表示。如果根据压缩的数据集可以恢复原来的数据集，则数据压缩是无损的，否则，数据压缩是有损的。</p>
<ul>
<li>主成分分析<br>主成分分析是对于原先提出的所有变量，建立尽可能少的新变量，使得这些新变量是两两不相关的，而且这些新变量在反映课题的信息方面尽可能保持原有的信息</li>
<li>小波变换</li>
<li>奇异值分解</li>
</ul>
</li>
<li><p>属性子集选择<br>手工消除无用或无关属性</p>
<ul>
<li>具有唯一值或近似唯一值的变量</li>
<li>具有单一值或近似单一值的变量</li>
<li>可以相互转换或同意义的变量，存在函数依赖的变量</li>
</ul>
</li>
<li><p>特征子集选取<br>(特征子集选取就是选取最小的特征属性集合，得到的数据挖掘结果与所有特征参加的数据挖掘结果相近或完全一致)</p>
</li>
<li>和建模过程集成(嵌入方法)<br>  多元回归分析、决策树方法<ul>
<li>进行独立的选取工作(过滤方法和包装方法)<br>例如：用关联分析选取重要变量、用决策树方法选取重要变量</li>
</ul>
</li>
</ul>
</li>
<li><p>行规约</p>
<ul>
<li>抽样<br>简单随机抽样(有放回和无放回)<br>分层抽样<br>簇抽样<br>自适应或渐进抽样<br>it’s difficulty to decide the number of observations in the sample, so at first  select little sample to mine, and then enlarge the sample gradually and estimate the result model to get a appropriate sample。</li>
<li>聚合</li>
<li>聚类</li>
</ul>
</li>
</ol>
<h3 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h3><p>将购买量转换为是否购买某类产品、由身份证号推出身份或年龄或性别、分布偏斜的取log，降低峰度取平方根</p>
<ol>
<li><p>函数变换</p>
</li>
<li><p>数值数据规范化处理<br>不同变量常常具有不同的单位和不同的取值及变异程度。   例如：第1个变量的单位是kg，第2个变量的单位是cm，那么将第1个变量与第2个变量的值相加有何意义？  不同变量自身具有相差较大的变异时，会使在计算出的关系系数中，不同变量所占的比重大不相同。为了消除量纲影响和变量自身变异大小和数值大小的影响，需要将数据规范化。</p>
<ul>
<li><p>最小-最大规范化</p>
<script type="math/tex; mode=display">
v'=\frac{v-min_A}{max_A-min_A}(new\_max_A-new\_min_A)+new\_min_A</script><p>A属性的原取值区间<script type="math/tex">[min_A，max_A]</script>目标新区间<script type="math/tex">[new\_min_A, new\_max_A]</script>目标新区建常为[0,1]<br>最小-最大规范化保留了原始数据值之间的关系。但是当有新数落在原数据区之外时，该方法将面临“越界”错误。另外，该方法受到孤立点的影响可能会比较大。</p>
</li>
<li><p>z-score规范化(标准化)<br>将属性A的值v转换为标准化值v’，均值为μ，标准差为σ</p>
<script type="math/tex; mode=display">
v’=\frac{(v-μ)}{σ}</script></li>
<li><p>十进制缩放规范化<br>将每个数值除以10的相同次方取整，A的值v规范化为v’，举例如年龄分段</p>
<script type="math/tex; mode=display">
v' = \frac{v}{10^j}</script></li>
</ul>
</li>
<li><p>数值数据离散化</p>
<ul>
<li>无监督离散化<br>二元化<br>分箱：等高、等宽、自定义</li>
<li>有监督离散化<br>基于熵<br>(基于熵的离散化：先分成熵总和最小的两个区间，再将熵最大的区间分成两个小区间，依次分下去直到需要的区间数。思想同二叉决策树)</li>
</ul>
</li>
<li><p>类别数据的数值化与数据泛化</p>
<ul>
<li><p>名义变量(标称变量nominal)的编码<br>one-hot编码(在做回归分析时，常需要一个全为0的参照变量)</p>
</li>
<li><p>有序变量(ordinal)的数值化<br>设序数变量的第i个对象的值为<script type="math/tex">x_i</script>，则用它在可能取值中的顺序<script type="math/tex">r_i</script>代替<script type="math/tex">x_i</script>(假设该变量有M个有序状态)<br>以顺序代替原值<script type="math/tex">r_i</script>→<script type="math/tex">x_i</script><br>规范化(将每个<script type="math/tex">r_i</script>映射到[0,1]区间)<script type="math/tex">z_i</script>→<script type="math/tex">x_i</script></p>
<script type="math/tex; mode=display">
z_i=\frac{r_i-1}{M-1}\qquad r_i∈\{1,...,M\} \\</script></li>
</ul>
</li>
</ol>
<ul>
<li>类别数据的泛化<br>   例如：地址：国家  省  地市   区县  街道(概念层次的上升，不关注值归入“其他”)</li>
</ul>
<h3 id="复杂数据类型的预处理：特征提取"><a href="#复杂数据类型的预处理：特征提取" class="headerlink" title="复杂数据类型的预处理：特征提取"></a><del>复杂数据类型的预处理：特征提取</del></h3><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><h3 id="多元线性回归方程的形式和假定"><a href="#多元线性回归方程的形式和假定" class="headerlink" title="多元线性回归方程的形式和假定"></a>多元线性回归方程的形式和假定</h3><script type="math/tex; mode=display">
Y=\beta_0+\beta_1X_1+\cdots+\beta_{p-1}X_{p-1}+\varepsilon</script><p>其中ε代表其他所有别的因素的总和</p>
<ol>
<li><p>假定X和Y之间存在线性关系：散点图、相关系数、假设检验</p>
</li>
<li><p>X相互独立：多重共线性检验(方差膨胀因子VIF)、变量选择法、回归优化法、pca等</p>
</li>
<li><p>ε独立同分布：<script type="math/tex">ε \sim N(0,σ ^2)</script></p>
</li>
<li><p>多项式回归</p>
<script type="math/tex; mode=display">
y=w_1x_1^2+w_2x_2^2+w_3x_1x_2+w_4x_1+w_5x_2+w_0</script><p>在线性回归方程中加入输入变量的指数项(包括变量的交互项)；指数的最高值称为degree；</p>
</li>
</ol>
<h3 id="方差分析与回归目标"><a href="#方差分析与回归目标" class="headerlink" title="方差分析与回归目标"></a>方差分析与回归目标</h3><script type="math/tex; mode=display">
\overline{Y}=\frac{1}{n}\sum_{i=1}^ny_i</script><ul>
<li><p>SST（total sum of squares）总离差和：反映了数据y1,y2,…,yn的波动大小；</p>
<script type="math/tex; mode=display">
SST=\sum_{i=1}^n(y_i-\overline{y})^2</script></li>
<li><p>SSE（error sum of squares）残差平方和：表示X不能解释的误差部分，反映除去Y与X1,X2,…,Xp-1之间的线性关系以外的因素引起的数据y1,y2,…yn的波动；</p>
<script type="math/tex; mode=display">
SSE=\sum_{i=1}^n(y_i-\hat{y_i})^2</script></li>
<li><p>SSR（regression sum of squares）回归平方和：反映了线性拟合值与它们的平均值的总偏差，即由变量X1,X2,…,Xp-1的变化引起的y1,y2…,yn的波动。若SSR=0，则每个拟合值相等，即y1,y2,…,yn不随着X1,X2,…,Xp-1的变化而变化</p>
<script type="math/tex; mode=display">
SSR=\sum_{i=1}^n(\hat{y_i}-\overline{y})^2</script></li>
<li><p>机器学习：<script type="math/tex">MSE = \frac{SSE} {n}</script><br>MAE(平均绝对误差)</p>
</li>
<li><p>目标： min{MSE}或min{SSE}<br>成本函数（损失函数：cost(θ)=MSE (θ)</p>
</li>
</ul>
<h3 id="回归参数求解"><a href="#回归参数求解" class="headerlink" title="回归参数求解"></a>回归参数求解</h3><ol>
<li><p>最小二乘</p>
<p>成本函数对参数求偏导，偏导为0，解方程组</p>
<ul>
<li><p>回归方程的矩阵形式：Y=Xθ </p>
<script type="math/tex; mode=display">
Y=Xθ\quad →\quad θ=(X^TX)^{-1}X^TY</script></li>
<li><p>自变量的相关性影响矩阵求逆</p>
</li>
<li><p>回归关系的显著性检验</p>
</li>
<li><p>回归系数的检验</p>
</li>
<li><p>误差项的正态性检验</p>
</li>
<li><p>最小二乘法矩阵求逆运算量大，所以适合于数据量小的情况</p>
</li>
</ul>
</li>
<li><p>梯度下降</p>
<script type="math/tex; mode=display">
θ^{(next\;step)}=θ-\eta\nabla_θMAE(θ)</script><p>不断更新θ，使损失函数趋向最小值</p>
<ul>
<li><p>批量梯度下降（Batch Gradient Desent）</p>
<script type="math/tex; mode=display">
\nabla_θMSE(θ)=\begin{Bmatrix}
\frac{\partial}{\partialθ_0}MSE(θ)\\
\frac{\partial}{\partialθ_1}MSE(θ)\\
\vdots\\
\frac{\partial}{\partialθ_n}MSE(θ)
\end{Bmatrix}=\frac{2}{m}X^T\cdot(X\cdotθ-y)</script><p>θ的每次更新都需要所有训练集的实例进行计算；批量法是一定朝着正确的梯度的；</p>
</li>
<li><p>随机梯度下降（Stochastic Gradient Desent）<br>θ的每次更新只需要随机选择一个训练实例进行计算；成本函数收敛快，但不一定达到最小，当成本函数为不规则函数时有优势。一般学习率逐渐减小​；适合大规模数据集​</p>
</li>
<li><p>小批量梯度下降（ Mini-batch  Gradient Desent）<br>θ的每次更新选择一组训练实例进行计算；兼具批量梯度下降的稳定性和随机梯度下降的快速性​</p>
</li>
<li><p>超参：学习率；迭代次数；多项式迭代中指数的最高项degree；</p>
</li>
<li><p>其他方法</p>
<ul>
<li>牛顿迭代法<br>利用目标函数f(x)的泰勒展开式并保留其线性部分来求解f(x)=0的近似解</li>
<li>牛顿法最值优化<br>求f’(x)=0时的根，使用了二阶导数，在每轮迭代中涉及海森矩阵的求逆，计算复杂度相当高，尤其在高维问题中几乎不可行。若能以较低的计算代价寻求海森矩阵的近似逆矩阵，则可以显著降低计算的时间，这就是拟牛顿法</li>
<li>常用的拟牛顿法有DFP、BFGS、SR1方法等</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="模型评估与误差来源分析"><a href="#模型评估与误差来源分析" class="headerlink" title="模型评估与误差来源分析"></a>模型评估与误差来源分析</h3><ol>
<li><p>训练误差：训练集上的模型预测误差</p>
</li>
<li><p>泛化误差：新数据集上的模型预测误差<br>测试集的误差作为泛化误差的无偏估计</p>
</li>
<li><p>评估</p>
<ul>
<li>好的分类模型<br><img src="../img/loading.gif" data-original="/img/datamining/curve1.png" style="width: 50%"><br>低训练误差<br>低泛化误差</li>
<li>拟合不足（欠拟合）：<br><img src="../img/loading.gif" data-original="/img/datamining/curve2.png" style="width: 50%"><br>较高训练误差<br>较高泛化误差</li>
<li>过拟合<br><img src="../img/loading.gif" data-original="/img/datamining/curve3.png" style="width: 50%"><br>低训练误差<br>较高泛化误差<br>解决办法：简化模型</li>
</ul>
</li>
<li><p>回归方程的评估复相关系数</p>
<script type="math/tex; mode=display">
R_p^2=\frac{SSR_p}{SST}=1-\frac{SSE_p}{SST}</script><p>在一个包含p-1个自变量的线性回归模型中（即模型中有p个参数），其中<script type="math/tex">SSE_p</script>和<script type="math/tex">SSR_p</script>分别表示拟合该模型的残差平方和及回归平方和，而总平方和SST是不随p变化的一个量；复相关系数越大则该回归方程描述因变量总变化量的比例越大；回归方程中不断添加自变量时，<script type="math/tex">R_p^2</script>的值单调递增，因此，当所有M个自变量都在回归方程中，<script type="math/tex">R_p^2</script>的值最大；实际应用中，当p增加时，候选模型所对应的R2值一般开始增加较快，后逐渐趋于平缓，即增加自变量已不能显著提高拟合精度，则将由较快增加到趋于平缓的分界点处的R2值所对应的那个回归方程为最优的回归方程；</p>
</li>
<li><p>修正的复相关系数</p>
<script type="math/tex; mode=display">
R_a^2=1-\left(\frac{n-1}{n-p}\right)\frac{SSE_p}{SST}=1-\frac{MSE_p}{\left(\frac{SST}{n-1}\right)}</script><p><script type="math/tex">R_p^2</script>中没有直接考虑模型中待估参数的个数P的作用。而一个好的模型应该既能充分反映 <script type="math/tex">y_i(1≤i≤n)</script>的变化，又包含较少的待估系数(因而包括较少的自变量)，因此将 P的控制引入到<script type="math/tex">R_p^2</script>中，得到它的一个修正量<script type="math/tex">R_a</script>.</p>
</li>
<li><p>模型误差的来源</p>
<ul>
<li>bias<br>模型类型的偏差，bias越大模型拟合度越低，欠拟合的可能性越大</li>
<li>Variance<br>模型复杂度造成的偏差，模型复杂度越大，variance越大，过拟合的可能性越大</li>
<li>Irreducibleerror<br>数据本身造成的误差，是不可减少的误差</li>
</ul>
</li>
</ol>
<h3 id="回归方程选择与正则化"><a href="#回归方程选择与正则化" class="headerlink" title="回归方程选择与正则化"></a>回归方程选择与正则化</h3><p>在一定的准则下选取对因变量影响较为显著的自变量，建立一个既合理又简单实用的回归模型</p>
<ol>
<li><p>数据集<br>选出最佳模型参数后，根据整个训练集重新训练模型</p>
<ul>
<li>训练集<br>训练集：练集构建模型<br>验证集：选择和调整模型</li>
<li>测试集：评估模型在新数据上的预测能力</li>
</ul>
</li>
<li><p>逐步回归法</p>
<ul>
<li><p>逐步回归法的基本步骤是依次拟合一系列回归方程，后一个回归方程在前一个的基础上增加或删除一个自变量</p>
</li>
<li><p>增加或删除某个自变量的准测用残差平方和的增加或减少量来衡量</p>
</li>
<li><p>一般采用偏F检验统计量</p>
<script type="math/tex; mode=display">
F=\frac{SSE(A)-SSE(A,X_k)}{\frac{SSE(A,X_k)}{n-l-1}}=\frac{SSR(X_k\mid A)}{MSE(A,X_k)}</script></li>
</ul>
</li>
<li><p>正则化(预防过拟合)<br>在模型拟合度和模型复杂度之间进行平衡</p>
<ul>
<li><p>岭回归</p>
<script type="math/tex; mode=display">
J(\theta)=MSE(\theta)+\alpha\frac{1}{2}\sum_{i=1}^n\theta_i^2</script></li>
<li><p>Lasso回归</p>
<script type="math/tex; mode=display">
J(\theta)=MSE(\theta)+\alpha\sum_{i=1}^n\left|\theta_i\right|</script><p>Lasso变量筛选能力强</p>
</li>
<li><p>Elastic Net</p>
<script type="math/tex; mode=display">
J(\theta)=MSE(\theta)+r\alpha\sum_{i=1}^n\left|\theta_i\right|+\frac{1-r}{2}\alpha\sum_{i=1}^n\theta_i^2</script></li>
</ul>
</li>
<li><p>其它问题<br>缺失值对回归的影响<br>类别变量如何加入回归方程<br>名义变量的编码</p>
<ul>
<li>one-hot编码</li>
<li>线性回归中，为避免k个二元变量的完全线性相关，往往取消1个二元变量（其对应取值作为参照水平）</li>
</ul>
<p>序数变量的编码</p>
<ul>
<li>pranks(职称)：助教、讲师、副教授、教授顺序编码：  0、1、2、3</li>
</ul>
<p>回归系数如何理解？</p>
<ul>
<li>系数:  影响方向、影响量自变量增减一个单位，因变量的变动量对类别变量，则表示当前水平相对于参照水平，因变量的变动量</li>
</ul>
<p>数值属性的重要性</p>
<p>数值变量的规范化</p>
<ul>
<li>标准化</li>
<li>最大最小规范化</li>
</ul>
</li>
</ol>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><h2 id="贝叶斯-k近邻-SVM"><a href="#贝叶斯-k近邻-SVM" class="headerlink" title="贝叶斯-k近邻-SVM"></a>贝叶斯-k近邻-SVM</h2><h2 id="分类器的评估与不平衡分布类"><a href="#分类器的评估与不平衡分布类" class="headerlink" title="分类器的评估与不平衡分布类"></a>分类器的评估与不平衡分布类</h2><h3 id="决策阈值"><a href="#决策阈值" class="headerlink" title="决策阈值"></a>决策阈值</h3><p>二分类的决策阈值：<strong>t=0.5</strong></p>
<h3 id="分类器的评估指标"><a href="#分类器的评估指标" class="headerlink" title="分类器的评估指标"></a>分类器的评估指标</h3><p><strong>二分类问题的混淆矩阵</strong>  </p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th>预测+</th>
<th>预测-</th>
<th>总</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">实际+</td>
<td>tp</td>
<td>fn</td>
<td>tp+fn</td>
</tr>
<tr>
<td style="text-align:left">实际-</td>
<td>fp</td>
<td>tn</td>
<td>fp+tn</td>
</tr>
<tr>
<td style="text-align:left">总</td>
<td>tp+fp</td>
<td>fn+tn</td>
<td>all</td>
</tr>
</tbody>
</table>
</div>
<p>准确率:  (tp+tn)/all        (识别率)<br>误分类率：(fp+fn)/all</p>
<p>Precision：返回的结果中真正和信息需求相关的文档所占的百分比tp/(tp+fp)<br>recall：所有和信息需求真正相关的文档中被检索系统返回的百分比tp/(tp+fn)</p>
<p>真正率：tp/(tp+fn)             tp/实际+            （灵敏度）<br>真负率：tn/(fp+tn)             tn/实际-            （特指度）<br>假正率：fp/(fp+tn)             fp/实际-<br>假负率：fn/(tp+fn)             fn/实际+</p>
<h3 id="评估方法（验证集的划分方法）"><a href="#评估方法（验证集的划分方法）" class="headerlink" title="评估方法（验证集的划分方法）"></a>评估方法（验证集的划分方法）</h3><h3 id="辅助图形"><a href="#辅助图形" class="headerlink" title="辅助图形"></a>辅助图形</h3><h3 id="不平衡分布类处理技术"><a href="#不平衡分布类处理技术" class="headerlink" title="不平衡分布类处理技术"></a>不平衡分布类处理技术</h3><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="感知器模型"><a href="#感知器模型" class="headerlink" title="感知器模型"></a>感知器模型</h3><p> <img src="../img/loading.gif" data-original="e:/blog/hexo/source/img/datamining/sensor.png" style="width :55%"></p>
<p><or>无法处理非线性分类问题</or><br>前馈式神经网络<br>可以进行二分类或者三分类</p>
<h3 id="BP算法"><a href="#BP算法" class="headerlink" title="BP算法"></a>BP算法</h3><p>它通过迭代地处理一组训练样本，将每个样本的网络预测值与实际值比较，根据二者之间的差异更新连接权值，以使得预测值与实际值之间的均方误差最小</p>
<p><or>存在梯度消失问题</or><br>ha</p>
<h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><h3 id="神经网络方法特点"><a href="#神经网络方法特点" class="headerlink" title="神经网络方法特点"></a>神经网络方法特点</h3><p>可解释性差</p>
<h2 id="组合分类与多分类"><a href="#组合分类与多分类" class="headerlink" title="组合分类与多分类"></a>组合分类与多分类</h2><h2 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h2><p>聚类除了进行对象的自然分类外，还可以实现数据压缩（保存类的质心，每个实例只保存所在类的质心的索引）；或者用于k近邻分类的预处理，每个实例都和同一类中的对象是近邻，可以降低计算近邻的复杂度</p>
<h3 id="聚类分析思想"><a href="#聚类分析思想" class="headerlink" title="聚类分析思想"></a>聚类分析思想</h3><h3 id="主要聚类方法"><a href="#主要聚类方法" class="headerlink" title="主要聚类方法"></a>主要聚类方法</h3><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3>
        <a id="gotop" href="#"><i class="iconfont icon-up-circle"></i></a>
        
        <br>
        <div id="gitalk-container">
        </div>
    </div>
</div>
    </div>
</div>

<footer class="footer">
    <ul class="list-inline text-center">
        <li>
            <a target="_blank" href="https://xn--i0v668g.com/">
                            <span>
                                <i class="iconfont icon-yang"></i>
                            </span>
            </a>
        </li>
        

        

        

        

        

    </ul>
    
    <p>
	to work harder
        <!-- 
	<span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span> 
----------------------------����if you are looking for my theme����---------------------------
	<a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a>
----------------------------------------------------------------------------------------------
	-->
        <a href="https://hexo.io/">Hexo</a></p>
</footer><!-- hexo-inject:begin --><!-- hexo-inject:end -->




<script>!function(e){var r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function t(){for(var c=0;c<r.length;c++)t=r[c],void 0,0<=(n=t.getBoundingClientRect()).top&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=r[c];t=o,n=function(){r=r.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}t(),e.addEventListener("scroll",function(){!function(t,n){clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)}(t,e)})}(this);</script></body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script src="/js/gitment.js"></script>


</html>
